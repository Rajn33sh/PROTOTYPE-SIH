{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7769e56a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2845147",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 7) (2414311061.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 7\u001b[1;36m\u001b[0m\n\u001b[1;33m    text's ka feature extraction(result will be a matrix)\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 7)\n"
     ]
    }
   ],
   "source": [
    "image ko preprosses \n",
    "normalization \n",
    "massed cnn for feature extracction or select the feature and extract \n",
    "\n",
    "normalization of single queries \n",
    "queries by lstm \n",
    "text's ka feature extraction(result will be a matrix)\n",
    "combine the feature extration and test the model (both will be in martix)\n",
    "\n",
    "give the image and check the output\n",
    "and check for classification  for image\n",
    "\n",
    "\n",
    "dimesnsility reduction \n",
    "from 10000 to 100 \n",
    "\n",
    "kam se kam feature mei predict kr de rha hai model...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c896f655",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load CSVs into dataframes\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m dataframes \u001b[38;5;241m=\u001b[39m [pd\u001b[38;5;241m.\u001b[39mread_csv(csv_file) \u001b[38;5;28;01mfor\u001b[39;00m csv_file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcsv_files\u001b[49m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Example: Viewing the first few rows of the first dataframe\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataframes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'csv_files' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSVs into dataframes\n",
    "dataframes = [pd.read_csv(csv_file) for csv_file in csv_files]\n",
    "\n",
    "# Example: Viewing the first few rows of the first dataframe\n",
    "print(dataframes[0].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a56aa8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Directory where the extracted images are stored\n",
    "extract_folder = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\extracted_data\"\n",
    "\n",
    "# Target directory to save processed images\n",
    "processed_dir = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\processed_images\"\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each subdirectory in the extract_folder\n",
    "for subdir in os.listdir(extract_folder):\n",
    "    subdir_path = os.path.join(extract_folder, subdir)\n",
    "\n",
    "    # Process only directories\n",
    "    if os.path.isdir(subdir_path):\n",
    "        for img_name in os.listdir(subdir_path):\n",
    "            img_path = os.path.join(subdir_path, img_name)\n",
    "\n",
    "            # Only process files\n",
    "            if os.path.isfile(img_path):\n",
    "                try:\n",
    "                    with Image.open(img_path) as img:\n",
    "                        # Example preprocessing: resizing the image to (224, 224)\n",
    "                        img_resized = img.resize((224, 224))\n",
    "                        # Save the preprocessed image\n",
    "                        img_resized.save(os.path.join(processed_dir, img_name))\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process {img_name}: {e}\")\n",
    "\n",
    "print(\"Image preprocessing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61addc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image preprocessing and normalization complete.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Directory where the extracted images are stored\n",
    "extract_folder = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\extracted_data\"\n",
    "\n",
    "# Target directory to save processed images\n",
    "processed_dir = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\processed_images\"\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each subdirectory in the extract_folder\n",
    "for subdir in os.listdir(extract_folder):\n",
    "    subdir_path = os.path.join(extract_folder, subdir)\n",
    "\n",
    "    # Process only directories\n",
    "    if os.path.isdir(subdir_path):\n",
    "        for img_name in os.listdir(subdir_path):\n",
    "            img_path = os.path.join(subdir_path, img_name)\n",
    "\n",
    "            # Only process files\n",
    "            if os.path.isfile(img_path):\n",
    "                try:\n",
    "                    with Image.open(img_path) as img:\n",
    "                        # Resize the image to (224, 224)\n",
    "                        img_resized = img.resize((224, 224))\n",
    "                        \n",
    "                        # Convert image to a NumPy array and normalize\n",
    "                        img_array = np.array(img_resized).astype(np.float32) / 255.0\n",
    "                        \n",
    "                        # Convert back to an image\n",
    "                        img_normalized = Image.fromarray((img_array * 255).astype(np.uint8))\n",
    "                        \n",
    "                        # Save the preprocessed image\n",
    "                        img_normalized.save(os.path.join(processed_dir, img_name))\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process {img_name}: {e}\")\n",
    "\n",
    "print(\"Image preprocessing and normalization complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64bd1166",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Define the directory where the images are processed\n",
    "processed_dir = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\processed_images\"\n",
    "\n",
    "# Directory to save extracted features\n",
    "features_dir = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\features\"\n",
    "os.makedirs(features_dir, exist_ok=True)\n",
    "\n",
    "# Define the image transformation to match the input of ResNet18\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the pre-trained ResNet18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Function to extract features from an image using the pre-trained model\n",
    "def extract_features(image_path, model, transform):\n",
    "    # Load and transform the image\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features = model(img_tensor)\n",
    "    \n",
    "    return features.squeeze().numpy()  # Remove batch dimension and convert to numpy array\n",
    "\n",
    "# Process each image and extract features\n",
    "for img_name in os.listdir(processed_dir):\n",
    "    img_path = os.path.join(processed_dir, img_name)\n",
    "    \n",
    "    if os.path.isfile(img_path):\n",
    "        try:\n",
    "            features = extract_features(img_path, model, transform)\n",
    "            np.save(os.path.join(features_dir, img_name.replace('.jpg', '.npy')), features)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract features from {img_name}: {e}\")\n",
    "\n",
    "print(\"Feature extraction complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f24dc7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Tokenized and padded queries:\n",
      "[[ 4  3  9 ...  0  0  0]\n",
      " [ 4  3  9 ...  0  0  0]\n",
      " [ 2  7  8 ...  0  0  0]\n",
      " ...\n",
      " [ 2 10  6 ... 34  0  0]\n",
      " [ 4  3 17 ...  0  0  0]\n",
      " [49  3  9 ... 19 52  0]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('questions_responses.csv')\n",
    "\n",
    "# Extract questions\n",
    "queries = df['Question'].values\n",
    "\n",
    "# Tokenization and encoding\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(queries)\n",
    "sequences = tokenizer.texts_to_sequences(queries)\n",
    "\n",
    "# Padding sequences to ensure uniform input size\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Print the results\n",
    "print(\"Tokenized and padded queries:\")\n",
    "print(padded_sequences)\n",
    "\n",
    "# Optionally save tokenizer for later use\n",
    "import pickle\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd9b1854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized tokenized and padded queries:\n",
      "[[-0.16075545 -0.73004776 -0.41757846 ... -0.63763507 -0.38327663\n",
      "  -0.20279155]\n",
      " [-0.16075545 -0.73004776 -0.41757846 ... -0.63763507 -0.38327663\n",
      "  -0.20279155]\n",
      " [-0.36384489  0.05020956 -0.54770169 ... -0.63763507 -0.38327663\n",
      "  -0.20279155]\n",
      " ...\n",
      " [-0.36384489  0.63540254 -0.80794814 ...  1.6445474  -0.38327663\n",
      "  -0.20279155]\n",
      " [-0.16075545 -0.73004776  0.62340738 ... -0.63763507 -0.38327663\n",
      "  -0.20279155]\n",
      " [ 4.40875704 -0.73004776 -0.41757846 ...  0.63770219  4.34191475\n",
      "  -0.20279155]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming `padded_sequences` is your tokenized and padded text data\n",
    "def normalize_sequences(sequences):\n",
    "    # Convert sequences to numpy array for normalization\n",
    "    sequences_np = np.array(sequences, dtype=float)\n",
    "    \n",
    "    # Initialize the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Normalize the sequences\n",
    "    normalized_sequences = scaler.fit_transform(sequences_np)\n",
    "    \n",
    "    return normalized_sequences\n",
    "\n",
    "# Example usage\n",
    "normalized_sequences = normalize_sequences(padded_sequences)\n",
    "print(\"Normalized tokenized and padded queries:\")\n",
    "print(normalized_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c3c4a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "313/313 [==============================] - 2s 4ms/step\n",
      "Extracted features:\n",
      "[-1.9939196e+00 -8.4555626e-01 -2.3387229e+00 -4.4125257e+00\n",
      " -3.1227643e+00  2.4605188e+00  1.0050197e+00 -6.3310319e-01\n",
      "  7.2966111e-01  3.8137548e+00  7.4052100e+00  3.9826109e+00\n",
      "  2.4990387e+00  6.6070523e+00  3.0617247e+00  8.6111641e+00\n",
      "  5.5946555e+00  4.8946190e+00  3.9981496e+00  7.3557539e+00\n",
      "  1.0201323e+01  4.5370078e+00  3.3402932e+00  6.7482436e-01\n",
      "  3.9036582e+00  2.3915422e+00  6.6188736e+00  3.5156238e+00\n",
      " -8.9494079e-02 -1.3304713e+00  3.3425145e+00  6.2310925e+00\n",
      "  4.9661999e+00  1.2399760e+00  1.9878036e+00  3.7653320e+00\n",
      "  4.0677128e+00  2.1187885e+00  5.5738254e+00  8.5208273e+00\n",
      "  1.0867703e+01  8.4217033e+00  1.0075059e+01  9.4817476e+00\n",
      "  7.7223659e+00  7.3388678e-01  8.7565298e+00  7.2358384e+00\n",
      "  2.9037430e+00  1.9532803e+00  1.7272254e+00 -1.6512737e+00\n",
      "  4.5064087e+00  5.0155101e+00  5.4110885e+00  6.6788139e+00\n",
      "  1.5066624e+00  5.3771424e+00  6.7508063e+00  1.0033520e+01\n",
      "  6.9514098e+00  2.8652630e+00  4.7446756e+00  5.5874243e+00\n",
      "  3.8475680e+00  3.8761005e+00  5.2529464e+00  3.1687710e+00\n",
      "  4.3750577e+00  3.2310052e+00  8.9103985e+00  6.5216680e+00\n",
      "  5.6162934e+00  5.9037981e+00  5.8048382e+00  3.1786039e+00\n",
      "  4.2669182e+00  9.0278254e+00  4.1721458e+00  7.2989182e+00\n",
      "  9.6852839e-01  3.0347674e+00  3.8586638e+00  1.6463610e+00\n",
      "  2.2830911e+00  6.1954489e+00  3.5301623e+00  2.7953377e-01\n",
      "  2.6489143e+00  2.5670140e+00  8.1152719e-01  7.3373270e+00\n",
      "  7.8371921e+00  3.4585860e+00  8.4376678e+00  8.3638973e+00\n",
      "  7.7846527e-01 -1.2664485e+00  7.4515849e-01 -7.5644273e-01\n",
      " -2.2307181e+00 -1.7457467e-01  2.1761351e+00  4.8446140e-01\n",
      "  3.1074655e+00  6.0059279e-01 -6.5165025e-01 -2.5512958e+00\n",
      " -8.8718563e-01 -2.1826322e+00  1.7251753e+00  4.6996584e+00\n",
      "  2.3691936e+00  6.9662805e+00  9.5274019e+00  1.1929747e+00\n",
      "  2.4891579e+00  5.5882260e-02  1.6568668e+00  5.6055446e+00\n",
      "  8.8918390e+00 -4.5498908e-01 -1.3574302e+00  3.7390945e+00\n",
      "  6.5604582e+00  3.2170756e+00  5.6376386e+00  1.0419971e+00\n",
      "  4.7341127e+00  4.8137250e+00 -2.6916981e+00  7.7429538e+00\n",
      "  7.8665709e+00  1.0519323e+01  4.9256606e+00  7.3532391e+00\n",
      "  2.6428401e+00  1.6886519e+00  6.5847349e+00  2.1072991e+00\n",
      "  3.6216772e+00  4.9611278e+00  4.7204418e+00  1.6685016e+00\n",
      "  3.4995489e+00  4.7224755e+00  2.3427837e+00  2.5745791e-01\n",
      " -2.6114583e+00 -3.1668241e+00  2.1277027e+00  1.4327852e+00\n",
      " -5.6709492e-01 -3.5540013e+00 -3.0599198e+00 -3.2734759e+00\n",
      "  7.3375076e-01 -5.2814841e-01 -1.5556542e+00 -1.2613004e-01\n",
      " -1.2115685e+00  7.5378102e-01  2.8165238e+00  1.2498591e+00\n",
      "  2.0162833e+00  5.1570529e-01  3.9573569e+00  3.5442848e+00\n",
      "  4.3086571e-01 -1.7087462e+00 -2.7787528e+00  1.5906227e+00\n",
      "  3.0214328e-01  2.4765434e+00 -1.5969223e+00 -1.5817001e+00\n",
      "  1.3352757e+00 -1.2393396e+00 -5.2410358e-01 -5.6556833e-01\n",
      " -8.5191166e-01 -1.7592551e+00 -5.6755316e-01 -1.2279451e+00\n",
      " -1.9910874e+00 -1.9157721e+00 -1.7433007e+00 -1.3250533e+00\n",
      " -1.9854438e+00  8.6911574e-02 -3.7149105e+00 -1.1975091e+00\n",
      " -1.7167119e+00 -2.2598038e+00 -5.5941691e+00 -2.7077627e+00\n",
      " -4.1545615e+00 -2.1202488e+00 -1.7225448e+00 -4.0412421e+00\n",
      " -1.1250272e+00 -3.3952062e+00 -3.4118419e+00 -2.8377070e+00\n",
      " -3.6249044e+00 -6.7083192e-01  1.9558273e-02 -1.5541300e+00\n",
      "  4.7885880e-01 -8.1789303e-01 -7.1701407e-01 -5.5754608e-01\n",
      " -2.4144695e+00 -9.8358876e-01 -4.8660883e-01 -7.9929374e-02\n",
      " -1.5017039e+00 -2.4706776e+00 -6.6743004e-01 -2.2169480e+00\n",
      " -1.4473389e+00 -6.9838357e-01 -2.2664576e+00  2.1026288e-01\n",
      "  1.0148997e+00 -7.1231210e-01 -3.6008015e+00  9.4646432e-02\n",
      " -2.1625514e+00 -3.5171890e+00 -1.9700810e-01 -2.5839812e-01\n",
      " -7.4893731e-01 -1.9394008e+00 -8.2786566e-01 -1.3049188e+00\n",
      "  7.0155549e-01 -4.3063417e-01  2.1375749e+00  1.2233374e+00\n",
      "  1.6591743e+00  1.2661316e+00 -1.1844991e+00 -2.6115041e+00\n",
      " -8.0806297e-01 -4.4624934e+00 -6.8982852e-01 -4.1708079e-01\n",
      " -3.0806515e-01 -2.7531905e+00 -1.5824459e+00 -2.0501788e+00\n",
      " -3.1854236e+00  3.2954324e-02 -2.3089345e+00  6.5503366e-02\n",
      " -5.7536447e-01 -2.5155590e+00 -2.9812703e+00 -1.4180932e+00\n",
      " -2.8801365e+00 -3.0076113e+00 -1.6988516e+00  1.5266622e+00\n",
      " -1.6596088e+00 -2.4867871e+00 -2.1491358e+00 -1.9834050e+00\n",
      " -1.0885596e+00  4.0927725e+00  2.5457280e+00  4.5667710e+00\n",
      "  5.9290204e+00  2.4298706e+00  3.1522512e+00  4.7987407e-01\n",
      " -1.1247426e+00  5.8169866e+00  5.3607926e+00  1.8440914e+00\n",
      "  6.8423042e+00  1.1800848e+00  1.7121195e+00 -1.2874779e+00\n",
      " -8.0277205e-01  1.7404926e+00  2.3696713e+00  2.0573771e+00\n",
      "  2.6922641e+00  8.2295138e-01  6.5198326e-01 -4.9442706e-01\n",
      " -3.3947769e-01 -1.8832749e-01  1.7885238e-02  3.0367968e+00\n",
      " -3.1570578e+00  1.8169973e+00  5.8787823e+00  5.3247957e+00\n",
      "  2.8705604e+00  3.9319816e+00  3.3237445e+00  6.0811296e+00\n",
      "  2.3405759e+00  2.9410131e+00  5.4096942e+00  5.3457804e+00\n",
      "  8.0758257e+00  8.1109161e+00  9.9027224e+00  1.0579746e+01\n",
      "  9.4773026e+00  1.2077886e+01  4.4437132e+00  1.1815689e+01\n",
      "  1.0303993e+01  1.0781896e+01  9.3057222e+00  1.3221822e+01\n",
      "  1.0846439e+01  6.6095090e+00  9.3018990e+00  4.3087707e+00\n",
      "  7.6564927e+00  5.0607743e+00  9.0874176e+00  6.8060599e-02\n",
      "  2.1572320e+00 -1.0457115e+00  3.1545444e+00  4.8331895e+00\n",
      " -2.3084815e+00  1.0312502e+00  1.0740141e+00  7.0089221e+00\n",
      "  5.9370713e+00  3.7341917e+00 -1.5413933e+00 -1.7523152e+00\n",
      " -5.0834972e-01  2.9945824e-01  1.6744512e+00  6.4430064e-01\n",
      " -3.5860856e+00  5.8941711e-02 -1.4088713e+00 -6.4012885e-01\n",
      "  9.0323180e-01  2.0193706e+00  3.8540633e+00 -2.0432128e-01\n",
      "  1.3015996e+00  2.6000946e+00 -6.1039537e-02  1.2747084e+00\n",
      "  6.9036179e+00  6.6460085e+00  3.1058207e+00  6.2810525e-02\n",
      "  1.5141369e+00 -2.2700302e-01  1.9197257e+00  1.3198303e+00\n",
      "  1.7928829e+00  3.6545184e-01  1.2819371e+00  1.9821123e+00\n",
      "  1.9112813e+00  3.3247540e+00  6.4848938e+00  7.1964035e+00\n",
      "  9.9480635e-01  3.5326545e+00  4.2690568e+00  2.9398377e+00\n",
      "  3.4160173e+00  5.6300731e+00  4.3875418e+00  3.9426222e+00\n",
      "  6.8264647e+00  3.0283000e+00  5.6899810e+00  3.6465485e+00\n",
      "  5.3480544e+00 -8.7738413e-01 -9.3249750e-01  2.7360790e+00\n",
      " -9.3264443e-01  2.2375236e-01  4.9510865e+00 -4.3357611e-01\n",
      " -3.3101764e-01 -2.9524820e+00 -5.9774041e-01  4.4128714e+00\n",
      "  1.5016766e+00  1.5389246e+00 -6.0793204e+00  7.4209386e-01\n",
      " -1.4186817e+00 -1.9073629e+00 -2.2681305e+00 -2.2757940e+00\n",
      " -3.1571476e+00 -4.4146566e+00 -3.1201148e+00 -3.4358411e+00\n",
      " -4.4541459e+00 -3.1045132e+00  3.3899417e+00 -2.1167917e+00\n",
      " -6.4098293e-01 -3.7413187e+00 -1.3702608e+00 -3.0608354e+00\n",
      "  2.3353963e+00 -5.6699014e+00  1.7583358e-01  1.9828567e-01\n",
      " -2.9101982e+00  1.1352407e+00 -4.7906899e+00 -2.4422245e+00\n",
      " -3.7268856e+00 -1.3642068e+00 -3.3467047e+00 -1.5671648e+00\n",
      "  3.1940751e+00 -2.1344917e+00 -2.4742734e+00 -7.8238082e-01\n",
      " -1.1137865e+00 -4.5033207e+00 -1.0750744e+00 -3.3606782e+00\n",
      " -4.6390862e+00 -4.6629558e+00 -1.0435282e+00  6.8380398e-01\n",
      " -8.1918645e-01 -1.7860026e+00 -2.7591531e+00 -2.1983519e+00\n",
      " -2.9404702e+00 -3.8765192e-02 -1.5955325e+00 -3.1969955e+00\n",
      "  1.6858904e+00 -3.0518668e+00 -1.9534476e+00  2.6471035e+00\n",
      "  2.1878254e+00 -3.1110954e+00 -4.3604870e+00 -9.1205138e-01\n",
      "  5.8819227e+00 -3.5111566e+00  1.5901314e+00  1.0050193e-01\n",
      " -1.4623649e+00  1.0232396e+00  2.1569314e+00  1.6823697e+00\n",
      "  2.8733897e-01 -1.0278692e+00 -1.3929478e+00 -4.2308397e+00\n",
      " -2.6608777e+00 -1.9744239e+00 -7.7947503e-01 -3.8107831e+00\n",
      "  4.5755213e-01  5.5139220e-01 -2.4862511e+00 -1.7247492e+00\n",
      " -4.7776618e+00 -1.3194066e+00 -1.4192213e+00 -1.8064376e+00\n",
      " -2.7020876e+00 -2.0972002e+00 -1.5282948e+00 -3.4230447e+00\n",
      " -1.5266711e+00 -3.0904489e+00 -3.3789289e+00 -2.4019203e-01\n",
      " -1.1913464e+00  3.6393855e+00 -1.1161515e+00 -1.2663022e+00\n",
      " -3.5577862e+00 -2.1116648e+00  3.3753699e-01 -6.1491852e+00\n",
      " -5.3795648e+00 -3.3388252e+00 -3.7377899e+00 -1.7751285e+00\n",
      " -5.5604786e-01  2.0576441e+00 -9.3948841e-01 -1.1986356e+00\n",
      " -2.0895677e+00  5.3960162e-01  2.1659747e-01 -2.4987733e+00\n",
      " -2.9863241e+00 -2.5183718e+00 -3.3592846e+00 -6.1289887e+00\n",
      " -6.4854372e-01 -1.8148730e+00  5.6223881e-01 -2.1178700e-01\n",
      " -1.5139343e+00 -1.2061387e+00 -1.5624262e+00 -1.0178812e+00\n",
      " -4.4890985e+00 -4.4499154e+00  2.8653342e-01  2.0391898e+00\n",
      " -1.6920041e-01  5.2400798e-01 -4.8709536e+00 -2.7823212e+00\n",
      " -4.3280678e+00 -2.2148230e+00 -4.3944421e+00 -3.8208742e+00\n",
      " -3.4446666e+00 -1.7222164e+00 -2.7819488e+00 -2.9122450e+00\n",
      " -3.6202753e+00  6.0598767e-01 -3.6765614e+00 -4.0140424e+00\n",
      " -3.3209579e+00 -1.1005994e+00 -2.7643225e-01 -5.6338224e+00\n",
      " -9.6630239e-01 -1.8759115e+00 -2.3521819e+00 -1.7863389e+00\n",
      " -1.4039406e+00 -2.1633394e+00 -3.1201656e+00 -2.7216187e+00\n",
      " -2.7281024e+00 -2.1830683e+00 -6.1142459e+00 -3.0204833e+00\n",
      " -5.4280454e-01 -1.7481856e+00  1.1813291e+00 -9.1956902e-01\n",
      " -3.5288618e+00 -2.9620578e+00 -1.0475310e-01  2.1381934e+00\n",
      " -4.8430347e+00 -2.7959943e+00 -1.5639552e+00 -1.2189798e+00\n",
      " -4.3197414e-01 -1.3138995e+00 -1.4741604e+00 -4.2477255e+00\n",
      "  5.3962862e-01 -3.1513679e+00  1.7850728e+00 -5.0134654e+00\n",
      " -1.8334749e+00 -7.0515186e-01 -5.7970750e-01 -3.9227436e+00\n",
      " -2.5290163e+00 -2.2264233e+00 -1.5183083e+00 -1.6221555e+00\n",
      " -4.2904112e-01 -3.6798215e+00 -3.5050306e+00  8.7500578e-01\n",
      " -1.5873286e+00 -4.3919539e+00 -2.6445956e+00 -1.5879468e+00\n",
      " -5.9405959e-01 -1.3002276e+00 -2.4275298e+00 -4.4333611e+00\n",
      "  3.5615790e+00 -2.6419458e+00 -3.4496155e+00  6.9729462e+00\n",
      "  3.6354921e+00 -1.9484106e+00  1.8434908e+00 -1.8927895e+00\n",
      " -1.5452069e+00  2.1999696e-01 -6.9028229e-01 -4.2414379e+00\n",
      "  2.2799165e+00 -3.4274008e+00 -1.6988693e+00 -4.2199540e+00\n",
      " -2.0603168e+00 -3.4022100e+00 -2.7387195e+00 -2.5910950e+00\n",
      "  2.2176220e+00 -1.3050113e+00  6.1989598e+00 -2.7798843e+00\n",
      " -2.1139958e+00 -2.0281465e+00 -2.9809322e+00  4.6724358e+00\n",
      " -3.4105651e+00 -4.4057932e+00  5.4659671e-01 -2.7437749e+00\n",
      " -3.0223627e+00 -2.9550862e+00  9.0281449e-02 -2.5569649e+00\n",
      "  5.8744317e-01  9.2155226e-02 -1.6554773e+00 -3.0282156e+00\n",
      " -4.5606771e-01 -3.6633959e-01 -9.2947960e-01 -2.5414097e+00\n",
      " -2.4759457e+00 -4.2071252e+00 -6.0801868e+00  2.7586418e-01\n",
      "  4.3230224e+00 -1.1128653e+00 -3.1637990e+00  7.8838623e-01\n",
      " -4.0510983e+00 -6.5385258e-01 -5.3992789e-02 -2.4814074e+00\n",
      "  1.8379760e-01 -2.1323807e+00 -4.1285176e+00 -4.3440074e-01\n",
      " -3.1511481e+00 -1.7326244e+00 -2.3155454e-01  4.7465198e-02\n",
      " -9.3367672e-01 -4.6448650e+00 -2.7970572e+00 -2.6494071e+00\n",
      " -3.4328526e-01 -4.5774727e+00 -9.8821568e-01 -7.3234636e-01\n",
      " -4.1877298e+00 -3.2186248e+00 -4.0624938e+00 -2.1906693e+00\n",
      "  5.4304701e-01 -2.9978611e+00  3.0431221e+00 -2.3191891e+00\n",
      " -6.8931051e-02  8.3938351e+00 -1.8880205e+00 -2.5566232e+00\n",
      " -8.3858466e-01 -2.5671110e+00 -4.3396142e-01 -3.1276128e+00\n",
      " -3.4475198e+00 -3.2465963e+00 -4.0633569e+00 -7.5113873e+00\n",
      " -3.5836246e+00  4.9751747e-02 -1.7953967e+00 -2.3901623e-01\n",
      "  1.8466169e+00  4.0622940e+00 -5.3129244e+00 -1.9117218e+00\n",
      "  2.6734695e+00 -3.6774833e+00 -5.1124830e+00 -2.7643316e+00\n",
      "  1.3815658e+00 -4.1313620e+00  2.7264378e+00 -1.5558192e-01\n",
      " -4.0845335e-02 -1.1757740e+00 -5.0650792e+00 -1.8161966e+00\n",
      " -5.3423268e-01 -1.2910435e+00  7.2475994e-01  5.9407568e-01\n",
      " -1.2285579e+00 -2.4835703e+00 -1.6285999e+00  2.6052395e-01\n",
      "  1.7143499e+00 -3.5942452e+00 -2.8884799e+00 -4.0051246e+00\n",
      " -3.2196639e+00 -1.8295245e+00  5.1223326e-01 -7.0626163e-01\n",
      " -3.9330454e+00 -3.1770578e-01 -2.2280674e+00 -6.0538025e+00\n",
      "  1.1058289e+00 -5.1201153e+00  1.3087488e+00 -3.9981735e-01\n",
      " -3.1392620e+00  3.9892993e+00 -3.7718573e+00 -2.5819662e+00\n",
      " -5.2637277e+00 -1.2397423e+00  1.1685716e+00 -2.7981911e+00\n",
      " -4.6840501e+00 -3.6548841e+00 -3.7537527e+00  3.1288113e-02\n",
      " -1.7078738e+00 -5.3499022e+00 -3.5428674e+00 -2.9186103e+00\n",
      " -1.3180321e+00  5.4340529e+00 -4.7752638e+00 -2.3788280e+00\n",
      " -1.6559899e-02 -9.7215313e-01 -7.3781693e-01 -6.8629801e-01\n",
      " -9.7874522e-01 -7.6974779e-01  7.3844308e-01 -4.0834708e+00\n",
      " -3.9010470e+00 -1.5001590e+00 -3.8788476e+00 -2.1746492e+00\n",
      " -9.8555547e-01 -5.1238406e-01 -1.5875995e+00 -1.0906308e+00\n",
      " -7.6636887e-01  1.2533933e+00  7.4113029e-01 -2.0195348e+00\n",
      "  1.6032138e+00 -1.6825759e+00  8.5868955e-01 -9.5201534e-01\n",
      " -2.3351102e+00  3.3393745e+00 -2.1054888e+00 -2.9180994e+00\n",
      " -2.1264777e+00 -2.0685399e+00 -5.3342420e-01  6.3026518e-01\n",
      "  1.3690025e+00 -3.0918221e+00 -4.7712436e+00  1.8220634e+00\n",
      " -2.5889032e+00 -2.7938271e+00 -3.4848619e+00  5.0482005e-01\n",
      "  2.8663638e+00 -2.9479389e+00 -3.7755225e+00  3.8571517e+00\n",
      "  1.1357422e+00 -1.1147201e+00 -1.1663015e+00 -2.7979705e+00\n",
      " -5.2766542e+00 -3.0663731e+00 -2.7378182e+00  1.2201118e-01\n",
      " -7.7789706e-01 -2.7592998e+00 -1.9375327e+00  2.7111340e-02\n",
      "  2.3546192e-01  1.5606791e-01 -5.5223856e+00 -2.1874368e+00\n",
      " -8.6189806e-01  1.2606708e+00 -5.2966125e-02  5.1558309e+00\n",
      " -5.0453824e-01 -4.3313036e+00  1.7646787e+00 -2.5486209e+00\n",
      " -3.7736020e+00 -1.9599577e+00 -2.0471752e+00 -2.5638576e+00\n",
      " -1.0092226e+00  2.4811065e+00 -2.6492572e+00 -3.0892034e+00\n",
      "  2.4489703e+00 -8.6058891e-01 -6.4061254e-01 -6.2572956e+00\n",
      " -3.1980715e+00 -1.4776329e+00 -2.1374648e+00  3.4797621e+00\n",
      " -7.4177778e-01 -1.2193381e+00 -1.7345785e+00  5.1132063e-03\n",
      "  1.4253308e+00  9.5127359e-02 -3.2582004e+00 -1.4071333e+00\n",
      " -2.7519395e+00  1.8764343e+00 -6.8902677e-01 -3.7619495e+00\n",
      " -1.4388189e+00 -1.2148277e+00 -2.6104827e+00  1.9347938e+00\n",
      "  2.7001092e-01 -1.3980728e+00 -4.4715662e+00  7.8806120e-01\n",
      " -5.4270196e+00 -1.0676922e+00 -4.2044091e+00 -5.2969885e-01\n",
      " -6.3372898e+00 -2.8104205e+00  3.3833361e+00 -2.5058007e+00\n",
      " -2.3970687e+00 -5.6405592e+00 -2.9094143e+00 -3.1877863e-01\n",
      " -1.7371469e+00 -2.7359350e+00 -3.6501079e+00 -1.9430411e+00\n",
      " -7.9828948e-02 -3.9232507e+00 -3.2717352e+00  1.8323456e+00\n",
      " -3.0945141e+00 -3.0686839e+00 -4.8254991e+00 -6.4368403e-01\n",
      " -2.9707170e+00 -4.6318336e+00 -2.0313132e+00  6.5425283e-01\n",
      " -2.4160602e+00 -2.3621473e+00 -4.5858727e+00  6.1263674e-01\n",
      " -1.0501320e+00 -1.4476343e+00 -1.0720382e+00 -3.9596753e+00\n",
      " -3.7776830e+00 -1.4383219e+00 -3.0732677e+00 -2.1022837e+00\n",
      " -1.9204046e+00 -2.9713254e+00 -1.3523822e+00  8.9885797e-03\n",
      " -4.2236562e+00 -2.5426385e+00 -8.0880290e-01 -2.6704931e+00\n",
      "  3.0349474e+00 -4.8217974e+00 -2.1830723e+00 -5.4794043e-02\n",
      " -2.3846807e+00 -2.0510867e+00  2.4600139e+00 -2.9052076e+00\n",
      "  6.3329945e+00 -9.6087176e-01 -7.6369262e-01 -1.7106798e+00\n",
      " -2.4767666e+00 -3.9139633e+00 -1.9978526e+00  1.5089788e+00\n",
      " -2.4276683e+00 -1.1621584e+00 -3.9304488e+00 -1.2055030e+00\n",
      "  5.3539997e-01 -1.7801806e+00 -2.8666351e+00 -6.8244755e-01\n",
      "  1.0260215e+00 -4.9348646e-01 -1.3140255e-01 -1.6667511e+00\n",
      " -2.6473124e+00 -3.8331764e+00 -1.8891780e+00 -2.5004699e+00\n",
      " -1.5798080e+00 -8.5195875e-01 -2.5042160e+00 -1.2804494e+00\n",
      " -1.2459463e+00 -1.1208673e+00 -2.0905542e+00 -9.4923958e-02\n",
      "  1.1930703e+00  8.5317856e-01  4.4032688e+00  4.0019350e+00\n",
      "  4.1523632e-01  7.3572546e-01  1.0540587e+00 -2.5120968e-01\n",
      "  9.2998421e-01  1.7904966e+00 -1.3486177e+00  8.0633914e-01\n",
      "  4.8312372e-01 -8.5601318e-01 -1.2547373e+00 -2.7571945e+00\n",
      " -6.8049145e-01 -2.3599148e+00 -1.3818531e-01 -2.5527167e+00\n",
      " -1.2411634e+00 -7.4724537e-01 -1.9643520e+00 -3.3836618e-01\n",
      " -1.1120626e+00 -1.7412913e+00  3.2453523e+00 -1.7753679e+00\n",
      "  1.9378021e+00 -2.7521628e-01 -1.5307586e+00  1.5053518e+00\n",
      " -9.9025470e-01 -1.1675348e+00 -1.0547174e+00  8.1667864e-01\n",
      "  3.9220229e-01 -2.0835922e+00 -2.5169868e+00 -4.1935763e+00\n",
      " -9.7508198e-01  5.5674133e+00  5.8121023e+00  1.3295478e+00\n",
      "  3.3260772e+00  5.0068846e+00  3.1887755e+00  5.1851544e+00\n",
      "  2.1173346e+00  1.7794693e+00  6.2960691e+00  5.1778574e+00\n",
      "  3.6616595e+00  2.4098606e+00  4.4120312e+00 -9.2818856e-01]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Parameters\n",
    "vocab_size = 10000  # Size of the tokenizer vocabulary\n",
    "embedding_dim = 128  # Dimension of embedding space\n",
    "lstm_units = 64  # Number of LSTM units\n",
    "input_length = padded_sequences.shape[1]  # Length of padded sequences\n",
    "num_classes = 10     # Number of classes for classification (adjust this as needed)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_length),\n",
    "    LSTM(lstm_units, return_sequences=False),\n",
    "    Dense(lstm_units, activation='relu')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fit the model (for demonstration, you would need proper training data and labels)\n",
    "# model.fit(padded_sequences, labels, epochs=10, batch_size=32)\n",
    "\n",
    "# Extract features\n",
    "text_features = model.predict(padded_sequences)\n",
    "print(\"Extracted features:\")\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb462565",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[-1.9939196e+00 -8.4555626e-01 -2.3387229e+00 -4.4125257e+00\n -3.1227643e+00  2.4605188e+00  1.0050197e+00 -6.3310319e-01\n  7.2966111e-01  3.8137548e+00  7.4052100e+00  3.9826109e+00\n  2.4990387e+00  6.6070523e+00  3.0617247e+00  8.6111641e+00\n  5.5946555e+00  4.8946190e+00  3.9981496e+00  7.3557539e+00\n  1.0201323e+01  4.5370078e+00  3.3402932e+00  6.7482436e-01\n  3.9036582e+00  2.3915422e+00  6.6188736e+00  3.5156238e+00\n -8.9494079e-02 -1.3304713e+00  3.3425145e+00  6.2310925e+00\n  4.9661999e+00  1.2399760e+00  1.9878036e+00  3.7653320e+00\n  4.0677128e+00  2.1187885e+00  5.5738254e+00  8.5208273e+00\n  1.0867703e+01  8.4217033e+00  1.0075059e+01  9.4817476e+00\n  7.7223659e+00  7.3388678e-01  8.7565298e+00  7.2358384e+00\n  2.9037430e+00  1.9532803e+00  1.7272254e+00 -1.6512737e+00\n  4.5064087e+00  5.0155101e+00  5.4110885e+00  6.6788139e+00\n  1.5066624e+00  5.3771424e+00  6.7508063e+00  1.0033520e+01\n  6.9514098e+00  2.8652630e+00  4.7446756e+00  5.5874243e+00\n  3.8475680e+00  3.8761005e+00  5.2529464e+00  3.1687710e+00\n  4.3750577e+00  3.2310052e+00  8.9103985e+00  6.5216680e+00\n  5.6162934e+00  5.9037981e+00  5.8048382e+00  3.1786039e+00\n  4.2669182e+00  9.0278254e+00  4.1721458e+00  7.2989182e+00\n  9.6852839e-01  3.0347674e+00  3.8586638e+00  1.6463610e+00\n  2.2830911e+00  6.1954489e+00  3.5301623e+00  2.7953377e-01\n  2.6489143e+00  2.5670140e+00  8.1152719e-01  7.3373270e+00\n  7.8371921e+00  3.4585860e+00  8.4376678e+00  8.3638973e+00\n  7.7846527e-01 -1.2664485e+00  7.4515849e-01 -7.5644273e-01\n -2.2307181e+00 -1.7457467e-01  2.1761351e+00  4.8446140e-01\n  3.1074655e+00  6.0059279e-01 -6.5165025e-01 -2.5512958e+00\n -8.8718563e-01 -2.1826322e+00  1.7251753e+00  4.6996584e+00\n  2.3691936e+00  6.9662805e+00  9.5274019e+00  1.1929747e+00\n  2.4891579e+00  5.5882260e-02  1.6568668e+00  5.6055446e+00\n  8.8918390e+00 -4.5498908e-01 -1.3574302e+00  3.7390945e+00\n  6.5604582e+00  3.2170756e+00  5.6376386e+00  1.0419971e+00\n  4.7341127e+00  4.8137250e+00 -2.6916981e+00  7.7429538e+00\n  7.8665709e+00  1.0519323e+01  4.9256606e+00  7.3532391e+00\n  2.6428401e+00  1.6886519e+00  6.5847349e+00  2.1072991e+00\n  3.6216772e+00  4.9611278e+00  4.7204418e+00  1.6685016e+00\n  3.4995489e+00  4.7224755e+00  2.3427837e+00  2.5745791e-01\n -2.6114583e+00 -3.1668241e+00  2.1277027e+00  1.4327852e+00\n -5.6709492e-01 -3.5540013e+00 -3.0599198e+00 -3.2734759e+00\n  7.3375076e-01 -5.2814841e-01 -1.5556542e+00 -1.2613004e-01\n -1.2115685e+00  7.5378102e-01  2.8165238e+00  1.2498591e+00\n  2.0162833e+00  5.1570529e-01  3.9573569e+00  3.5442848e+00\n  4.3086571e-01 -1.7087462e+00 -2.7787528e+00  1.5906227e+00\n  3.0214328e-01  2.4765434e+00 -1.5969223e+00 -1.5817001e+00\n  1.3352757e+00 -1.2393396e+00 -5.2410358e-01 -5.6556833e-01\n -8.5191166e-01 -1.7592551e+00 -5.6755316e-01 -1.2279451e+00\n -1.9910874e+00 -1.9157721e+00 -1.7433007e+00 -1.3250533e+00\n -1.9854438e+00  8.6911574e-02 -3.7149105e+00 -1.1975091e+00\n -1.7167119e+00 -2.2598038e+00 -5.5941691e+00 -2.7077627e+00\n -4.1545615e+00 -2.1202488e+00 -1.7225448e+00 -4.0412421e+00\n -1.1250272e+00 -3.3952062e+00 -3.4118419e+00 -2.8377070e+00\n -3.6249044e+00 -6.7083192e-01  1.9558273e-02 -1.5541300e+00\n  4.7885880e-01 -8.1789303e-01 -7.1701407e-01 -5.5754608e-01\n -2.4144695e+00 -9.8358876e-01 -4.8660883e-01 -7.9929374e-02\n -1.5017039e+00 -2.4706776e+00 -6.6743004e-01 -2.2169480e+00\n -1.4473389e+00 -6.9838357e-01 -2.2664576e+00  2.1026288e-01\n  1.0148997e+00 -7.1231210e-01 -3.6008015e+00  9.4646432e-02\n -2.1625514e+00 -3.5171890e+00 -1.9700810e-01 -2.5839812e-01\n -7.4893731e-01 -1.9394008e+00 -8.2786566e-01 -1.3049188e+00\n  7.0155549e-01 -4.3063417e-01  2.1375749e+00  1.2233374e+00\n  1.6591743e+00  1.2661316e+00 -1.1844991e+00 -2.6115041e+00\n -8.0806297e-01 -4.4624934e+00 -6.8982852e-01 -4.1708079e-01\n -3.0806515e-01 -2.7531905e+00 -1.5824459e+00 -2.0501788e+00\n -3.1854236e+00  3.2954324e-02 -2.3089345e+00  6.5503366e-02\n -5.7536447e-01 -2.5155590e+00 -2.9812703e+00 -1.4180932e+00\n -2.8801365e+00 -3.0076113e+00 -1.6988516e+00  1.5266622e+00\n -1.6596088e+00 -2.4867871e+00 -2.1491358e+00 -1.9834050e+00\n -1.0885596e+00  4.0927725e+00  2.5457280e+00  4.5667710e+00\n  5.9290204e+00  2.4298706e+00  3.1522512e+00  4.7987407e-01\n -1.1247426e+00  5.8169866e+00  5.3607926e+00  1.8440914e+00\n  6.8423042e+00  1.1800848e+00  1.7121195e+00 -1.2874779e+00\n -8.0277205e-01  1.7404926e+00  2.3696713e+00  2.0573771e+00\n  2.6922641e+00  8.2295138e-01  6.5198326e-01 -4.9442706e-01\n -3.3947769e-01 -1.8832749e-01  1.7885238e-02  3.0367968e+00\n -3.1570578e+00  1.8169973e+00  5.8787823e+00  5.3247957e+00\n  2.8705604e+00  3.9319816e+00  3.3237445e+00  6.0811296e+00\n  2.3405759e+00  2.9410131e+00  5.4096942e+00  5.3457804e+00\n  8.0758257e+00  8.1109161e+00  9.9027224e+00  1.0579746e+01\n  9.4773026e+00  1.2077886e+01  4.4437132e+00  1.1815689e+01\n  1.0303993e+01  1.0781896e+01  9.3057222e+00  1.3221822e+01\n  1.0846439e+01  6.6095090e+00  9.3018990e+00  4.3087707e+00\n  7.6564927e+00  5.0607743e+00  9.0874176e+00  6.8060599e-02\n  2.1572320e+00 -1.0457115e+00  3.1545444e+00  4.8331895e+00\n -2.3084815e+00  1.0312502e+00  1.0740141e+00  7.0089221e+00\n  5.9370713e+00  3.7341917e+00 -1.5413933e+00 -1.7523152e+00\n -5.0834972e-01  2.9945824e-01  1.6744512e+00  6.4430064e-01\n -3.5860856e+00  5.8941711e-02 -1.4088713e+00 -6.4012885e-01\n  9.0323180e-01  2.0193706e+00  3.8540633e+00 -2.0432128e-01\n  1.3015996e+00  2.6000946e+00 -6.1039537e-02  1.2747084e+00\n  6.9036179e+00  6.6460085e+00  3.1058207e+00  6.2810525e-02\n  1.5141369e+00 -2.2700302e-01  1.9197257e+00  1.3198303e+00\n  1.7928829e+00  3.6545184e-01  1.2819371e+00  1.9821123e+00\n  1.9112813e+00  3.3247540e+00  6.4848938e+00  7.1964035e+00\n  9.9480635e-01  3.5326545e+00  4.2690568e+00  2.9398377e+00\n  3.4160173e+00  5.6300731e+00  4.3875418e+00  3.9426222e+00\n  6.8264647e+00  3.0283000e+00  5.6899810e+00  3.6465485e+00\n  5.3480544e+00 -8.7738413e-01 -9.3249750e-01  2.7360790e+00\n -9.3264443e-01  2.2375236e-01  4.9510865e+00 -4.3357611e-01\n -3.3101764e-01 -2.9524820e+00 -5.9774041e-01  4.4128714e+00\n  1.5016766e+00  1.5389246e+00 -6.0793204e+00  7.4209386e-01\n -1.4186817e+00 -1.9073629e+00 -2.2681305e+00 -2.2757940e+00\n -3.1571476e+00 -4.4146566e+00 -3.1201148e+00 -3.4358411e+00\n -4.4541459e+00 -3.1045132e+00  3.3899417e+00 -2.1167917e+00\n -6.4098293e-01 -3.7413187e+00 -1.3702608e+00 -3.0608354e+00\n  2.3353963e+00 -5.6699014e+00  1.7583358e-01  1.9828567e-01\n -2.9101982e+00  1.1352407e+00 -4.7906899e+00 -2.4422245e+00\n -3.7268856e+00 -1.3642068e+00 -3.3467047e+00 -1.5671648e+00\n  3.1940751e+00 -2.1344917e+00 -2.4742734e+00 -7.8238082e-01\n -1.1137865e+00 -4.5033207e+00 -1.0750744e+00 -3.3606782e+00\n -4.6390862e+00 -4.6629558e+00 -1.0435282e+00  6.8380398e-01\n -8.1918645e-01 -1.7860026e+00 -2.7591531e+00 -2.1983519e+00\n -2.9404702e+00 -3.8765192e-02 -1.5955325e+00 -3.1969955e+00\n  1.6858904e+00 -3.0518668e+00 -1.9534476e+00  2.6471035e+00\n  2.1878254e+00 -3.1110954e+00 -4.3604870e+00 -9.1205138e-01\n  5.8819227e+00 -3.5111566e+00  1.5901314e+00  1.0050193e-01\n -1.4623649e+00  1.0232396e+00  2.1569314e+00  1.6823697e+00\n  2.8733897e-01 -1.0278692e+00 -1.3929478e+00 -4.2308397e+00\n -2.6608777e+00 -1.9744239e+00 -7.7947503e-01 -3.8107831e+00\n  4.5755213e-01  5.5139220e-01 -2.4862511e+00 -1.7247492e+00\n -4.7776618e+00 -1.3194066e+00 -1.4192213e+00 -1.8064376e+00\n -2.7020876e+00 -2.0972002e+00 -1.5282948e+00 -3.4230447e+00\n -1.5266711e+00 -3.0904489e+00 -3.3789289e+00 -2.4019203e-01\n -1.1913464e+00  3.6393855e+00 -1.1161515e+00 -1.2663022e+00\n -3.5577862e+00 -2.1116648e+00  3.3753699e-01 -6.1491852e+00\n -5.3795648e+00 -3.3388252e+00 -3.7377899e+00 -1.7751285e+00\n -5.5604786e-01  2.0576441e+00 -9.3948841e-01 -1.1986356e+00\n -2.0895677e+00  5.3960162e-01  2.1659747e-01 -2.4987733e+00\n -2.9863241e+00 -2.5183718e+00 -3.3592846e+00 -6.1289887e+00\n -6.4854372e-01 -1.8148730e+00  5.6223881e-01 -2.1178700e-01\n -1.5139343e+00 -1.2061387e+00 -1.5624262e+00 -1.0178812e+00\n -4.4890985e+00 -4.4499154e+00  2.8653342e-01  2.0391898e+00\n -1.6920041e-01  5.2400798e-01 -4.8709536e+00 -2.7823212e+00\n -4.3280678e+00 -2.2148230e+00 -4.3944421e+00 -3.8208742e+00\n -3.4446666e+00 -1.7222164e+00 -2.7819488e+00 -2.9122450e+00\n -3.6202753e+00  6.0598767e-01 -3.6765614e+00 -4.0140424e+00\n -3.3209579e+00 -1.1005994e+00 -2.7643225e-01 -5.6338224e+00\n -9.6630239e-01 -1.8759115e+00 -2.3521819e+00 -1.7863389e+00\n -1.4039406e+00 -2.1633394e+00 -3.1201656e+00 -2.7216187e+00\n -2.7281024e+00 -2.1830683e+00 -6.1142459e+00 -3.0204833e+00\n -5.4280454e-01 -1.7481856e+00  1.1813291e+00 -9.1956902e-01\n -3.5288618e+00 -2.9620578e+00 -1.0475310e-01  2.1381934e+00\n -4.8430347e+00 -2.7959943e+00 -1.5639552e+00 -1.2189798e+00\n -4.3197414e-01 -1.3138995e+00 -1.4741604e+00 -4.2477255e+00\n  5.3962862e-01 -3.1513679e+00  1.7850728e+00 -5.0134654e+00\n -1.8334749e+00 -7.0515186e-01 -5.7970750e-01 -3.9227436e+00\n -2.5290163e+00 -2.2264233e+00 -1.5183083e+00 -1.6221555e+00\n -4.2904112e-01 -3.6798215e+00 -3.5050306e+00  8.7500578e-01\n -1.5873286e+00 -4.3919539e+00 -2.6445956e+00 -1.5879468e+00\n -5.9405959e-01 -1.3002276e+00 -2.4275298e+00 -4.4333611e+00\n  3.5615790e+00 -2.6419458e+00 -3.4496155e+00  6.9729462e+00\n  3.6354921e+00 -1.9484106e+00  1.8434908e+00 -1.8927895e+00\n -1.5452069e+00  2.1999696e-01 -6.9028229e-01 -4.2414379e+00\n  2.2799165e+00 -3.4274008e+00 -1.6988693e+00 -4.2199540e+00\n -2.0603168e+00 -3.4022100e+00 -2.7387195e+00 -2.5910950e+00\n  2.2176220e+00 -1.3050113e+00  6.1989598e+00 -2.7798843e+00\n -2.1139958e+00 -2.0281465e+00 -2.9809322e+00  4.6724358e+00\n -3.4105651e+00 -4.4057932e+00  5.4659671e-01 -2.7437749e+00\n -3.0223627e+00 -2.9550862e+00  9.0281449e-02 -2.5569649e+00\n  5.8744317e-01  9.2155226e-02 -1.6554773e+00 -3.0282156e+00\n -4.5606771e-01 -3.6633959e-01 -9.2947960e-01 -2.5414097e+00\n -2.4759457e+00 -4.2071252e+00 -6.0801868e+00  2.7586418e-01\n  4.3230224e+00 -1.1128653e+00 -3.1637990e+00  7.8838623e-01\n -4.0510983e+00 -6.5385258e-01 -5.3992789e-02 -2.4814074e+00\n  1.8379760e-01 -2.1323807e+00 -4.1285176e+00 -4.3440074e-01\n -3.1511481e+00 -1.7326244e+00 -2.3155454e-01  4.7465198e-02\n -9.3367672e-01 -4.6448650e+00 -2.7970572e+00 -2.6494071e+00\n -3.4328526e-01 -4.5774727e+00 -9.8821568e-01 -7.3234636e-01\n -4.1877298e+00 -3.2186248e+00 -4.0624938e+00 -2.1906693e+00\n  5.4304701e-01 -2.9978611e+00  3.0431221e+00 -2.3191891e+00\n -6.8931051e-02  8.3938351e+00 -1.8880205e+00 -2.5566232e+00\n -8.3858466e-01 -2.5671110e+00 -4.3396142e-01 -3.1276128e+00\n -3.4475198e+00 -3.2465963e+00 -4.0633569e+00 -7.5113873e+00\n -3.5836246e+00  4.9751747e-02 -1.7953967e+00 -2.3901623e-01\n  1.8466169e+00  4.0622940e+00 -5.3129244e+00 -1.9117218e+00\n  2.6734695e+00 -3.6774833e+00 -5.1124830e+00 -2.7643316e+00\n  1.3815658e+00 -4.1313620e+00  2.7264378e+00 -1.5558192e-01\n -4.0845335e-02 -1.1757740e+00 -5.0650792e+00 -1.8161966e+00\n -5.3423268e-01 -1.2910435e+00  7.2475994e-01  5.9407568e-01\n -1.2285579e+00 -2.4835703e+00 -1.6285999e+00  2.6052395e-01\n  1.7143499e+00 -3.5942452e+00 -2.8884799e+00 -4.0051246e+00\n -3.2196639e+00 -1.8295245e+00  5.1223326e-01 -7.0626163e-01\n -3.9330454e+00 -3.1770578e-01 -2.2280674e+00 -6.0538025e+00\n  1.1058289e+00 -5.1201153e+00  1.3087488e+00 -3.9981735e-01\n -3.1392620e+00  3.9892993e+00 -3.7718573e+00 -2.5819662e+00\n -5.2637277e+00 -1.2397423e+00  1.1685716e+00 -2.7981911e+00\n -4.6840501e+00 -3.6548841e+00 -3.7537527e+00  3.1288113e-02\n -1.7078738e+00 -5.3499022e+00 -3.5428674e+00 -2.9186103e+00\n -1.3180321e+00  5.4340529e+00 -4.7752638e+00 -2.3788280e+00\n -1.6559899e-02 -9.7215313e-01 -7.3781693e-01 -6.8629801e-01\n -9.7874522e-01 -7.6974779e-01  7.3844308e-01 -4.0834708e+00\n -3.9010470e+00 -1.5001590e+00 -3.8788476e+00 -2.1746492e+00\n -9.8555547e-01 -5.1238406e-01 -1.5875995e+00 -1.0906308e+00\n -7.6636887e-01  1.2533933e+00  7.4113029e-01 -2.0195348e+00\n  1.6032138e+00 -1.6825759e+00  8.5868955e-01 -9.5201534e-01\n -2.3351102e+00  3.3393745e+00 -2.1054888e+00 -2.9180994e+00\n -2.1264777e+00 -2.0685399e+00 -5.3342420e-01  6.3026518e-01\n  1.3690025e+00 -3.0918221e+00 -4.7712436e+00  1.8220634e+00\n -2.5889032e+00 -2.7938271e+00 -3.4848619e+00  5.0482005e-01\n  2.8663638e+00 -2.9479389e+00 -3.7755225e+00  3.8571517e+00\n  1.1357422e+00 -1.1147201e+00 -1.1663015e+00 -2.7979705e+00\n -5.2766542e+00 -3.0663731e+00 -2.7378182e+00  1.2201118e-01\n -7.7789706e-01 -2.7592998e+00 -1.9375327e+00  2.7111340e-02\n  2.3546192e-01  1.5606791e-01 -5.5223856e+00 -2.1874368e+00\n -8.6189806e-01  1.2606708e+00 -5.2966125e-02  5.1558309e+00\n -5.0453824e-01 -4.3313036e+00  1.7646787e+00 -2.5486209e+00\n -3.7736020e+00 -1.9599577e+00 -2.0471752e+00 -2.5638576e+00\n -1.0092226e+00  2.4811065e+00 -2.6492572e+00 -3.0892034e+00\n  2.4489703e+00 -8.6058891e-01 -6.4061254e-01 -6.2572956e+00\n -3.1980715e+00 -1.4776329e+00 -2.1374648e+00  3.4797621e+00\n -7.4177778e-01 -1.2193381e+00 -1.7345785e+00  5.1132063e-03\n  1.4253308e+00  9.5127359e-02 -3.2582004e+00 -1.4071333e+00\n -2.7519395e+00  1.8764343e+00 -6.8902677e-01 -3.7619495e+00\n -1.4388189e+00 -1.2148277e+00 -2.6104827e+00  1.9347938e+00\n  2.7001092e-01 -1.3980728e+00 -4.4715662e+00  7.8806120e-01\n -5.4270196e+00 -1.0676922e+00 -4.2044091e+00 -5.2969885e-01\n -6.3372898e+00 -2.8104205e+00  3.3833361e+00 -2.5058007e+00\n -2.3970687e+00 -5.6405592e+00 -2.9094143e+00 -3.1877863e-01\n -1.7371469e+00 -2.7359350e+00 -3.6501079e+00 -1.9430411e+00\n -7.9828948e-02 -3.9232507e+00 -3.2717352e+00  1.8323456e+00\n -3.0945141e+00 -3.0686839e+00 -4.8254991e+00 -6.4368403e-01\n -2.9707170e+00 -4.6318336e+00 -2.0313132e+00  6.5425283e-01\n -2.4160602e+00 -2.3621473e+00 -4.5858727e+00  6.1263674e-01\n -1.0501320e+00 -1.4476343e+00 -1.0720382e+00 -3.9596753e+00\n -3.7776830e+00 -1.4383219e+00 -3.0732677e+00 -2.1022837e+00\n -1.9204046e+00 -2.9713254e+00 -1.3523822e+00  8.9885797e-03\n -4.2236562e+00 -2.5426385e+00 -8.0880290e-01 -2.6704931e+00\n  3.0349474e+00 -4.8217974e+00 -2.1830723e+00 -5.4794043e-02\n -2.3846807e+00 -2.0510867e+00  2.4600139e+00 -2.9052076e+00\n  6.3329945e+00 -9.6087176e-01 -7.6369262e-01 -1.7106798e+00\n -2.4767666e+00 -3.9139633e+00 -1.9978526e+00  1.5089788e+00\n -2.4276683e+00 -1.1621584e+00 -3.9304488e+00 -1.2055030e+00\n  5.3539997e-01 -1.7801806e+00 -2.8666351e+00 -6.8244755e-01\n  1.0260215e+00 -4.9348646e-01 -1.3140255e-01 -1.6667511e+00\n -2.6473124e+00 -3.8331764e+00 -1.8891780e+00 -2.5004699e+00\n -1.5798080e+00 -8.5195875e-01 -2.5042160e+00 -1.2804494e+00\n -1.2459463e+00 -1.1208673e+00 -2.0905542e+00 -9.4923958e-02\n  1.1930703e+00  8.5317856e-01  4.4032688e+00  4.0019350e+00\n  4.1523632e-01  7.3572546e-01  1.0540587e+00 -2.5120968e-01\n  9.2998421e-01  1.7904966e+00 -1.3486177e+00  8.0633914e-01\n  4.8312372e-01 -8.5601318e-01 -1.2547373e+00 -2.7571945e+00\n -6.8049145e-01 -2.3599148e+00 -1.3818531e-01 -2.5527167e+00\n -1.2411634e+00 -7.4724537e-01 -1.9643520e+00 -3.3836618e-01\n -1.1120626e+00 -1.7412913e+00  3.2453523e+00 -1.7753679e+00\n  1.9378021e+00 -2.7521628e-01 -1.5307586e+00  1.5053518e+00\n -9.9025470e-01 -1.1675348e+00 -1.0547174e+00  8.1667864e-01\n  3.9220229e-01 -2.0835922e+00 -2.5169868e+00 -4.1935763e+00\n -9.7508198e-01  5.5674133e+00  5.8121023e+00  1.3295478e+00\n  3.3260772e+00  5.0068846e+00  3.1887755e+00  5.1851544e+00\n  2.1173346e+00  1.7794693e+00  6.2960691e+00  5.1778574e+00\n  3.6616595e+00  2.4098606e+00  4.4120312e+00 -9.2818856e-01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming `query_features` is your text feature matrix\u001b[39;00m\n\u001b[0;32m      5\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m----> 6\u001b[0m normalized_query_features \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_set_output.py:273\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 273\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    276\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    277\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    278\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    279\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:1061\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1046\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1047\u001b[0m             (\n\u001b[0;32m   1048\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1057\u001b[0m         )\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1060\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1063\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\preprocessing\\_data.py:876\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\preprocessing\\_data.py:912\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \n\u001b[0;32m    882\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    911\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 912\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    914\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    919\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py:989\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    983\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    984\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m             )\n\u001b[1;32m--> 989\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    992\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    994\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    995\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[-1.9939196e+00 -8.4555626e-01 -2.3387229e+00 -4.4125257e+00\n -3.1227643e+00  2.4605188e+00  1.0050197e+00 -6.3310319e-01\n  7.2966111e-01  3.8137548e+00  7.4052100e+00  3.9826109e+00\n  2.4990387e+00  6.6070523e+00  3.0617247e+00  8.6111641e+00\n  5.5946555e+00  4.8946190e+00  3.9981496e+00  7.3557539e+00\n  1.0201323e+01  4.5370078e+00  3.3402932e+00  6.7482436e-01\n  3.9036582e+00  2.3915422e+00  6.6188736e+00  3.5156238e+00\n -8.9494079e-02 -1.3304713e+00  3.3425145e+00  6.2310925e+00\n  4.9661999e+00  1.2399760e+00  1.9878036e+00  3.7653320e+00\n  4.0677128e+00  2.1187885e+00  5.5738254e+00  8.5208273e+00\n  1.0867703e+01  8.4217033e+00  1.0075059e+01  9.4817476e+00\n  7.7223659e+00  7.3388678e-01  8.7565298e+00  7.2358384e+00\n  2.9037430e+00  1.9532803e+00  1.7272254e+00 -1.6512737e+00\n  4.5064087e+00  5.0155101e+00  5.4110885e+00  6.6788139e+00\n  1.5066624e+00  5.3771424e+00  6.7508063e+00  1.0033520e+01\n  6.9514098e+00  2.8652630e+00  4.7446756e+00  5.5874243e+00\n  3.8475680e+00  3.8761005e+00  5.2529464e+00  3.1687710e+00\n  4.3750577e+00  3.2310052e+00  8.9103985e+00  6.5216680e+00\n  5.6162934e+00  5.9037981e+00  5.8048382e+00  3.1786039e+00\n  4.2669182e+00  9.0278254e+00  4.1721458e+00  7.2989182e+00\n  9.6852839e-01  3.0347674e+00  3.8586638e+00  1.6463610e+00\n  2.2830911e+00  6.1954489e+00  3.5301623e+00  2.7953377e-01\n  2.6489143e+00  2.5670140e+00  8.1152719e-01  7.3373270e+00\n  7.8371921e+00  3.4585860e+00  8.4376678e+00  8.3638973e+00\n  7.7846527e-01 -1.2664485e+00  7.4515849e-01 -7.5644273e-01\n -2.2307181e+00 -1.7457467e-01  2.1761351e+00  4.8446140e-01\n  3.1074655e+00  6.0059279e-01 -6.5165025e-01 -2.5512958e+00\n -8.8718563e-01 -2.1826322e+00  1.7251753e+00  4.6996584e+00\n  2.3691936e+00  6.9662805e+00  9.5274019e+00  1.1929747e+00\n  2.4891579e+00  5.5882260e-02  1.6568668e+00  5.6055446e+00\n  8.8918390e+00 -4.5498908e-01 -1.3574302e+00  3.7390945e+00\n  6.5604582e+00  3.2170756e+00  5.6376386e+00  1.0419971e+00\n  4.7341127e+00  4.8137250e+00 -2.6916981e+00  7.7429538e+00\n  7.8665709e+00  1.0519323e+01  4.9256606e+00  7.3532391e+00\n  2.6428401e+00  1.6886519e+00  6.5847349e+00  2.1072991e+00\n  3.6216772e+00  4.9611278e+00  4.7204418e+00  1.6685016e+00\n  3.4995489e+00  4.7224755e+00  2.3427837e+00  2.5745791e-01\n -2.6114583e+00 -3.1668241e+00  2.1277027e+00  1.4327852e+00\n -5.6709492e-01 -3.5540013e+00 -3.0599198e+00 -3.2734759e+00\n  7.3375076e-01 -5.2814841e-01 -1.5556542e+00 -1.2613004e-01\n -1.2115685e+00  7.5378102e-01  2.8165238e+00  1.2498591e+00\n  2.0162833e+00  5.1570529e-01  3.9573569e+00  3.5442848e+00\n  4.3086571e-01 -1.7087462e+00 -2.7787528e+00  1.5906227e+00\n  3.0214328e-01  2.4765434e+00 -1.5969223e+00 -1.5817001e+00\n  1.3352757e+00 -1.2393396e+00 -5.2410358e-01 -5.6556833e-01\n -8.5191166e-01 -1.7592551e+00 -5.6755316e-01 -1.2279451e+00\n -1.9910874e+00 -1.9157721e+00 -1.7433007e+00 -1.3250533e+00\n -1.9854438e+00  8.6911574e-02 -3.7149105e+00 -1.1975091e+00\n -1.7167119e+00 -2.2598038e+00 -5.5941691e+00 -2.7077627e+00\n -4.1545615e+00 -2.1202488e+00 -1.7225448e+00 -4.0412421e+00\n -1.1250272e+00 -3.3952062e+00 -3.4118419e+00 -2.8377070e+00\n -3.6249044e+00 -6.7083192e-01  1.9558273e-02 -1.5541300e+00\n  4.7885880e-01 -8.1789303e-01 -7.1701407e-01 -5.5754608e-01\n -2.4144695e+00 -9.8358876e-01 -4.8660883e-01 -7.9929374e-02\n -1.5017039e+00 -2.4706776e+00 -6.6743004e-01 -2.2169480e+00\n -1.4473389e+00 -6.9838357e-01 -2.2664576e+00  2.1026288e-01\n  1.0148997e+00 -7.1231210e-01 -3.6008015e+00  9.4646432e-02\n -2.1625514e+00 -3.5171890e+00 -1.9700810e-01 -2.5839812e-01\n -7.4893731e-01 -1.9394008e+00 -8.2786566e-01 -1.3049188e+00\n  7.0155549e-01 -4.3063417e-01  2.1375749e+00  1.2233374e+00\n  1.6591743e+00  1.2661316e+00 -1.1844991e+00 -2.6115041e+00\n -8.0806297e-01 -4.4624934e+00 -6.8982852e-01 -4.1708079e-01\n -3.0806515e-01 -2.7531905e+00 -1.5824459e+00 -2.0501788e+00\n -3.1854236e+00  3.2954324e-02 -2.3089345e+00  6.5503366e-02\n -5.7536447e-01 -2.5155590e+00 -2.9812703e+00 -1.4180932e+00\n -2.8801365e+00 -3.0076113e+00 -1.6988516e+00  1.5266622e+00\n -1.6596088e+00 -2.4867871e+00 -2.1491358e+00 -1.9834050e+00\n -1.0885596e+00  4.0927725e+00  2.5457280e+00  4.5667710e+00\n  5.9290204e+00  2.4298706e+00  3.1522512e+00  4.7987407e-01\n -1.1247426e+00  5.8169866e+00  5.3607926e+00  1.8440914e+00\n  6.8423042e+00  1.1800848e+00  1.7121195e+00 -1.2874779e+00\n -8.0277205e-01  1.7404926e+00  2.3696713e+00  2.0573771e+00\n  2.6922641e+00  8.2295138e-01  6.5198326e-01 -4.9442706e-01\n -3.3947769e-01 -1.8832749e-01  1.7885238e-02  3.0367968e+00\n -3.1570578e+00  1.8169973e+00  5.8787823e+00  5.3247957e+00\n  2.8705604e+00  3.9319816e+00  3.3237445e+00  6.0811296e+00\n  2.3405759e+00  2.9410131e+00  5.4096942e+00  5.3457804e+00\n  8.0758257e+00  8.1109161e+00  9.9027224e+00  1.0579746e+01\n  9.4773026e+00  1.2077886e+01  4.4437132e+00  1.1815689e+01\n  1.0303993e+01  1.0781896e+01  9.3057222e+00  1.3221822e+01\n  1.0846439e+01  6.6095090e+00  9.3018990e+00  4.3087707e+00\n  7.6564927e+00  5.0607743e+00  9.0874176e+00  6.8060599e-02\n  2.1572320e+00 -1.0457115e+00  3.1545444e+00  4.8331895e+00\n -2.3084815e+00  1.0312502e+00  1.0740141e+00  7.0089221e+00\n  5.9370713e+00  3.7341917e+00 -1.5413933e+00 -1.7523152e+00\n -5.0834972e-01  2.9945824e-01  1.6744512e+00  6.4430064e-01\n -3.5860856e+00  5.8941711e-02 -1.4088713e+00 -6.4012885e-01\n  9.0323180e-01  2.0193706e+00  3.8540633e+00 -2.0432128e-01\n  1.3015996e+00  2.6000946e+00 -6.1039537e-02  1.2747084e+00\n  6.9036179e+00  6.6460085e+00  3.1058207e+00  6.2810525e-02\n  1.5141369e+00 -2.2700302e-01  1.9197257e+00  1.3198303e+00\n  1.7928829e+00  3.6545184e-01  1.2819371e+00  1.9821123e+00\n  1.9112813e+00  3.3247540e+00  6.4848938e+00  7.1964035e+00\n  9.9480635e-01  3.5326545e+00  4.2690568e+00  2.9398377e+00\n  3.4160173e+00  5.6300731e+00  4.3875418e+00  3.9426222e+00\n  6.8264647e+00  3.0283000e+00  5.6899810e+00  3.6465485e+00\n  5.3480544e+00 -8.7738413e-01 -9.3249750e-01  2.7360790e+00\n -9.3264443e-01  2.2375236e-01  4.9510865e+00 -4.3357611e-01\n -3.3101764e-01 -2.9524820e+00 -5.9774041e-01  4.4128714e+00\n  1.5016766e+00  1.5389246e+00 -6.0793204e+00  7.4209386e-01\n -1.4186817e+00 -1.9073629e+00 -2.2681305e+00 -2.2757940e+00\n -3.1571476e+00 -4.4146566e+00 -3.1201148e+00 -3.4358411e+00\n -4.4541459e+00 -3.1045132e+00  3.3899417e+00 -2.1167917e+00\n -6.4098293e-01 -3.7413187e+00 -1.3702608e+00 -3.0608354e+00\n  2.3353963e+00 -5.6699014e+00  1.7583358e-01  1.9828567e-01\n -2.9101982e+00  1.1352407e+00 -4.7906899e+00 -2.4422245e+00\n -3.7268856e+00 -1.3642068e+00 -3.3467047e+00 -1.5671648e+00\n  3.1940751e+00 -2.1344917e+00 -2.4742734e+00 -7.8238082e-01\n -1.1137865e+00 -4.5033207e+00 -1.0750744e+00 -3.3606782e+00\n -4.6390862e+00 -4.6629558e+00 -1.0435282e+00  6.8380398e-01\n -8.1918645e-01 -1.7860026e+00 -2.7591531e+00 -2.1983519e+00\n -2.9404702e+00 -3.8765192e-02 -1.5955325e+00 -3.1969955e+00\n  1.6858904e+00 -3.0518668e+00 -1.9534476e+00  2.6471035e+00\n  2.1878254e+00 -3.1110954e+00 -4.3604870e+00 -9.1205138e-01\n  5.8819227e+00 -3.5111566e+00  1.5901314e+00  1.0050193e-01\n -1.4623649e+00  1.0232396e+00  2.1569314e+00  1.6823697e+00\n  2.8733897e-01 -1.0278692e+00 -1.3929478e+00 -4.2308397e+00\n -2.6608777e+00 -1.9744239e+00 -7.7947503e-01 -3.8107831e+00\n  4.5755213e-01  5.5139220e-01 -2.4862511e+00 -1.7247492e+00\n -4.7776618e+00 -1.3194066e+00 -1.4192213e+00 -1.8064376e+00\n -2.7020876e+00 -2.0972002e+00 -1.5282948e+00 -3.4230447e+00\n -1.5266711e+00 -3.0904489e+00 -3.3789289e+00 -2.4019203e-01\n -1.1913464e+00  3.6393855e+00 -1.1161515e+00 -1.2663022e+00\n -3.5577862e+00 -2.1116648e+00  3.3753699e-01 -6.1491852e+00\n -5.3795648e+00 -3.3388252e+00 -3.7377899e+00 -1.7751285e+00\n -5.5604786e-01  2.0576441e+00 -9.3948841e-01 -1.1986356e+00\n -2.0895677e+00  5.3960162e-01  2.1659747e-01 -2.4987733e+00\n -2.9863241e+00 -2.5183718e+00 -3.3592846e+00 -6.1289887e+00\n -6.4854372e-01 -1.8148730e+00  5.6223881e-01 -2.1178700e-01\n -1.5139343e+00 -1.2061387e+00 -1.5624262e+00 -1.0178812e+00\n -4.4890985e+00 -4.4499154e+00  2.8653342e-01  2.0391898e+00\n -1.6920041e-01  5.2400798e-01 -4.8709536e+00 -2.7823212e+00\n -4.3280678e+00 -2.2148230e+00 -4.3944421e+00 -3.8208742e+00\n -3.4446666e+00 -1.7222164e+00 -2.7819488e+00 -2.9122450e+00\n -3.6202753e+00  6.0598767e-01 -3.6765614e+00 -4.0140424e+00\n -3.3209579e+00 -1.1005994e+00 -2.7643225e-01 -5.6338224e+00\n -9.6630239e-01 -1.8759115e+00 -2.3521819e+00 -1.7863389e+00\n -1.4039406e+00 -2.1633394e+00 -3.1201656e+00 -2.7216187e+00\n -2.7281024e+00 -2.1830683e+00 -6.1142459e+00 -3.0204833e+00\n -5.4280454e-01 -1.7481856e+00  1.1813291e+00 -9.1956902e-01\n -3.5288618e+00 -2.9620578e+00 -1.0475310e-01  2.1381934e+00\n -4.8430347e+00 -2.7959943e+00 -1.5639552e+00 -1.2189798e+00\n -4.3197414e-01 -1.3138995e+00 -1.4741604e+00 -4.2477255e+00\n  5.3962862e-01 -3.1513679e+00  1.7850728e+00 -5.0134654e+00\n -1.8334749e+00 -7.0515186e-01 -5.7970750e-01 -3.9227436e+00\n -2.5290163e+00 -2.2264233e+00 -1.5183083e+00 -1.6221555e+00\n -4.2904112e-01 -3.6798215e+00 -3.5050306e+00  8.7500578e-01\n -1.5873286e+00 -4.3919539e+00 -2.6445956e+00 -1.5879468e+00\n -5.9405959e-01 -1.3002276e+00 -2.4275298e+00 -4.4333611e+00\n  3.5615790e+00 -2.6419458e+00 -3.4496155e+00  6.9729462e+00\n  3.6354921e+00 -1.9484106e+00  1.8434908e+00 -1.8927895e+00\n -1.5452069e+00  2.1999696e-01 -6.9028229e-01 -4.2414379e+00\n  2.2799165e+00 -3.4274008e+00 -1.6988693e+00 -4.2199540e+00\n -2.0603168e+00 -3.4022100e+00 -2.7387195e+00 -2.5910950e+00\n  2.2176220e+00 -1.3050113e+00  6.1989598e+00 -2.7798843e+00\n -2.1139958e+00 -2.0281465e+00 -2.9809322e+00  4.6724358e+00\n -3.4105651e+00 -4.4057932e+00  5.4659671e-01 -2.7437749e+00\n -3.0223627e+00 -2.9550862e+00  9.0281449e-02 -2.5569649e+00\n  5.8744317e-01  9.2155226e-02 -1.6554773e+00 -3.0282156e+00\n -4.5606771e-01 -3.6633959e-01 -9.2947960e-01 -2.5414097e+00\n -2.4759457e+00 -4.2071252e+00 -6.0801868e+00  2.7586418e-01\n  4.3230224e+00 -1.1128653e+00 -3.1637990e+00  7.8838623e-01\n -4.0510983e+00 -6.5385258e-01 -5.3992789e-02 -2.4814074e+00\n  1.8379760e-01 -2.1323807e+00 -4.1285176e+00 -4.3440074e-01\n -3.1511481e+00 -1.7326244e+00 -2.3155454e-01  4.7465198e-02\n -9.3367672e-01 -4.6448650e+00 -2.7970572e+00 -2.6494071e+00\n -3.4328526e-01 -4.5774727e+00 -9.8821568e-01 -7.3234636e-01\n -4.1877298e+00 -3.2186248e+00 -4.0624938e+00 -2.1906693e+00\n  5.4304701e-01 -2.9978611e+00  3.0431221e+00 -2.3191891e+00\n -6.8931051e-02  8.3938351e+00 -1.8880205e+00 -2.5566232e+00\n -8.3858466e-01 -2.5671110e+00 -4.3396142e-01 -3.1276128e+00\n -3.4475198e+00 -3.2465963e+00 -4.0633569e+00 -7.5113873e+00\n -3.5836246e+00  4.9751747e-02 -1.7953967e+00 -2.3901623e-01\n  1.8466169e+00  4.0622940e+00 -5.3129244e+00 -1.9117218e+00\n  2.6734695e+00 -3.6774833e+00 -5.1124830e+00 -2.7643316e+00\n  1.3815658e+00 -4.1313620e+00  2.7264378e+00 -1.5558192e-01\n -4.0845335e-02 -1.1757740e+00 -5.0650792e+00 -1.8161966e+00\n -5.3423268e-01 -1.2910435e+00  7.2475994e-01  5.9407568e-01\n -1.2285579e+00 -2.4835703e+00 -1.6285999e+00  2.6052395e-01\n  1.7143499e+00 -3.5942452e+00 -2.8884799e+00 -4.0051246e+00\n -3.2196639e+00 -1.8295245e+00  5.1223326e-01 -7.0626163e-01\n -3.9330454e+00 -3.1770578e-01 -2.2280674e+00 -6.0538025e+00\n  1.1058289e+00 -5.1201153e+00  1.3087488e+00 -3.9981735e-01\n -3.1392620e+00  3.9892993e+00 -3.7718573e+00 -2.5819662e+00\n -5.2637277e+00 -1.2397423e+00  1.1685716e+00 -2.7981911e+00\n -4.6840501e+00 -3.6548841e+00 -3.7537527e+00  3.1288113e-02\n -1.7078738e+00 -5.3499022e+00 -3.5428674e+00 -2.9186103e+00\n -1.3180321e+00  5.4340529e+00 -4.7752638e+00 -2.3788280e+00\n -1.6559899e-02 -9.7215313e-01 -7.3781693e-01 -6.8629801e-01\n -9.7874522e-01 -7.6974779e-01  7.3844308e-01 -4.0834708e+00\n -3.9010470e+00 -1.5001590e+00 -3.8788476e+00 -2.1746492e+00\n -9.8555547e-01 -5.1238406e-01 -1.5875995e+00 -1.0906308e+00\n -7.6636887e-01  1.2533933e+00  7.4113029e-01 -2.0195348e+00\n  1.6032138e+00 -1.6825759e+00  8.5868955e-01 -9.5201534e-01\n -2.3351102e+00  3.3393745e+00 -2.1054888e+00 -2.9180994e+00\n -2.1264777e+00 -2.0685399e+00 -5.3342420e-01  6.3026518e-01\n  1.3690025e+00 -3.0918221e+00 -4.7712436e+00  1.8220634e+00\n -2.5889032e+00 -2.7938271e+00 -3.4848619e+00  5.0482005e-01\n  2.8663638e+00 -2.9479389e+00 -3.7755225e+00  3.8571517e+00\n  1.1357422e+00 -1.1147201e+00 -1.1663015e+00 -2.7979705e+00\n -5.2766542e+00 -3.0663731e+00 -2.7378182e+00  1.2201118e-01\n -7.7789706e-01 -2.7592998e+00 -1.9375327e+00  2.7111340e-02\n  2.3546192e-01  1.5606791e-01 -5.5223856e+00 -2.1874368e+00\n -8.6189806e-01  1.2606708e+00 -5.2966125e-02  5.1558309e+00\n -5.0453824e-01 -4.3313036e+00  1.7646787e+00 -2.5486209e+00\n -3.7736020e+00 -1.9599577e+00 -2.0471752e+00 -2.5638576e+00\n -1.0092226e+00  2.4811065e+00 -2.6492572e+00 -3.0892034e+00\n  2.4489703e+00 -8.6058891e-01 -6.4061254e-01 -6.2572956e+00\n -3.1980715e+00 -1.4776329e+00 -2.1374648e+00  3.4797621e+00\n -7.4177778e-01 -1.2193381e+00 -1.7345785e+00  5.1132063e-03\n  1.4253308e+00  9.5127359e-02 -3.2582004e+00 -1.4071333e+00\n -2.7519395e+00  1.8764343e+00 -6.8902677e-01 -3.7619495e+00\n -1.4388189e+00 -1.2148277e+00 -2.6104827e+00  1.9347938e+00\n  2.7001092e-01 -1.3980728e+00 -4.4715662e+00  7.8806120e-01\n -5.4270196e+00 -1.0676922e+00 -4.2044091e+00 -5.2969885e-01\n -6.3372898e+00 -2.8104205e+00  3.3833361e+00 -2.5058007e+00\n -2.3970687e+00 -5.6405592e+00 -2.9094143e+00 -3.1877863e-01\n -1.7371469e+00 -2.7359350e+00 -3.6501079e+00 -1.9430411e+00\n -7.9828948e-02 -3.9232507e+00 -3.2717352e+00  1.8323456e+00\n -3.0945141e+00 -3.0686839e+00 -4.8254991e+00 -6.4368403e-01\n -2.9707170e+00 -4.6318336e+00 -2.0313132e+00  6.5425283e-01\n -2.4160602e+00 -2.3621473e+00 -4.5858727e+00  6.1263674e-01\n -1.0501320e+00 -1.4476343e+00 -1.0720382e+00 -3.9596753e+00\n -3.7776830e+00 -1.4383219e+00 -3.0732677e+00 -2.1022837e+00\n -1.9204046e+00 -2.9713254e+00 -1.3523822e+00  8.9885797e-03\n -4.2236562e+00 -2.5426385e+00 -8.0880290e-01 -2.6704931e+00\n  3.0349474e+00 -4.8217974e+00 -2.1830723e+00 -5.4794043e-02\n -2.3846807e+00 -2.0510867e+00  2.4600139e+00 -2.9052076e+00\n  6.3329945e+00 -9.6087176e-01 -7.6369262e-01 -1.7106798e+00\n -2.4767666e+00 -3.9139633e+00 -1.9978526e+00  1.5089788e+00\n -2.4276683e+00 -1.1621584e+00 -3.9304488e+00 -1.2055030e+00\n  5.3539997e-01 -1.7801806e+00 -2.8666351e+00 -6.8244755e-01\n  1.0260215e+00 -4.9348646e-01 -1.3140255e-01 -1.6667511e+00\n -2.6473124e+00 -3.8331764e+00 -1.8891780e+00 -2.5004699e+00\n -1.5798080e+00 -8.5195875e-01 -2.5042160e+00 -1.2804494e+00\n -1.2459463e+00 -1.1208673e+00 -2.0905542e+00 -9.4923958e-02\n  1.1930703e+00  8.5317856e-01  4.4032688e+00  4.0019350e+00\n  4.1523632e-01  7.3572546e-01  1.0540587e+00 -2.5120968e-01\n  9.2998421e-01  1.7904966e+00 -1.3486177e+00  8.0633914e-01\n  4.8312372e-01 -8.5601318e-01 -1.2547373e+00 -2.7571945e+00\n -6.8049145e-01 -2.3599148e+00 -1.3818531e-01 -2.5527167e+00\n -1.2411634e+00 -7.4724537e-01 -1.9643520e+00 -3.3836618e-01\n -1.1120626e+00 -1.7412913e+00  3.2453523e+00 -1.7753679e+00\n  1.9378021e+00 -2.7521628e-01 -1.5307586e+00  1.5053518e+00\n -9.9025470e-01 -1.1675348e+00 -1.0547174e+00  8.1667864e-01\n  3.9220229e-01 -2.0835922e+00 -2.5169868e+00 -4.1935763e+00\n -9.7508198e-01  5.5674133e+00  5.8121023e+00  1.3295478e+00\n  3.3260772e+00  5.0068846e+00  3.1887755e+00  5.1851544e+00\n  2.1173346e+00  1.7794693e+00  6.2960691e+00  5.1778574e+00\n  3.6616595e+00  2.4098606e+00  4.4120312e+00 -9.2818856e-01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `query_features` is your text feature matrix\n",
    "scaler = StandardScaler()\n",
    "normalized_query_features = scaler.fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13240ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # Use the last time step\n",
    "        return out\n",
    "\n",
    "# Example instantiation and usage\n",
    "lstm_model = LSTMModel(input_size=embedding_dim, hidden_size=lstm_units, output_size=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dbe9f582",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def extract_text_features(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()  # Mean pooling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "195e0853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_features shape: (100, 1280)\n",
      "labels shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"combined_features shape: {combined_features.shape}\")\n",
    "print(f\"labels shape: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ee3b109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated labels shape: (100,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = combined_features.shape[0]\n",
    "num_classes = 5  # Number of categories, adjust as needed\n",
    "\n",
    "# Create labels with the same number of samples as combined_features\n",
    "labels = np.random.randint(0, num_classes, num_samples)\n",
    "\n",
    "print(f\"Updated labels shape: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7921b187",
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming `image_features` and `text_features` are numpy arrays\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m combined_features \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train a classifier\u001b[39;00m\n\u001b[0;32m      7\u001b[0m classifier \u001b[38;5;241m=\u001b[39m LogisticRegression()\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Assuming `image_features` and `text_features` are numpy arrays\n",
    "combined_features = np.concatenate((features, text_features), axis=1)\n",
    "\n",
    "# Train a classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(combined_features, labels)  # `labels` should be your target variable\n",
    "\n",
    "# Test the classifier\n",
    "predictions = classifier.predict(combined_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944ec3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce dimensionality\n",
    "pca = PCA(n_components=100)\n",
    "reduced_features = pca.fit_transform(combined_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a05bb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset combined_features shape: (100, 1280)\n"
     ]
    }
   ],
   "source": [
    "# Assuming you need to select a subset of combined_features\n",
    "subset_size = labels.shape[0]\n",
    "combined_features_subset = combined_features[:subset_size]\n",
    "\n",
    "print(f\"Subset combined_features shape: {combined_features_subset.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bbb66bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.20\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Generate labels\n",
    "num_samples = combined_features.shape[0]\n",
    "num_classes = 5  # Number of categories\n",
    "labels = np.random.randint(0, num_classes, num_samples)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a896cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "# Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pre-trained models\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "cnn_model = models.resnet18(pretrained=True).to(device)\n",
    "cnn_model.eval()\n",
    "\n",
    "# Image preprocessing\n",
    "def preprocess_image(img_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        features = cnn_model(img_tensor)\n",
    "    return features.squeeze().cpu().numpy()\n",
    "\n",
    "# Text feature extraction\n",
    "def extract_text_features(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9a6e29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined features shape: (1, 1768)\n"
     ]
    }
   ],
   "source": [
    "# Example data\n",
    "image_path = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\images\\002_0087.jpg\"\n",
    "text_query = 'What\\'s the color?'\n",
    "\n",
    "# Extract features\n",
    "image_features = preprocess_image(image_path)\n",
    "text_features = extract_text_features(text_query)\n",
    "\n",
    "# Ensure they are 2D\n",
    "image_features = image_features.reshape(1, -1)\n",
    "text_features = text_features.reshape(1, -1)\n",
    "\n",
    "# Combine features\n",
    "combined_features = np.concatenate((image_features, text_features), axis=1)\n",
    "\n",
    "print(\"Combined features shape:\", combined_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6b1e17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.40\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Simulated data\n",
    "num_samples = 100  # Sample size\n",
    "num_features_image = 512  # Example number of image features\n",
    "num_features_text = 768  # Example number of text features\n",
    "num_classes = 5\n",
    "\n",
    "# Generate dummy data\n",
    "np.random.seed(102)\n",
    "combined_features = np.random.rand(num_samples, num_features_image + num_features_text)\n",
    "labels = np.random.randint(0, num_classes, num_samples)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalization\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "# Dimensionality Reduction\n",
    "pca = PCA(n_components=min(70, X_train_normalized.shape[1]))  # Use 70 or fewer components\n",
    "X_train_reduced = pca.fit_transform(X_train_normalized)\n",
    "X_test_reduced = pca.transform(X_test_normalized)\n",
    "\n",
    "# Train the classifier\n",
    "classifier = LogisticRegression(max_iter=1000)  # Increased max_iter to ensure convergence\n",
    "classifier.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions = classifier.predict(X_test_reduced)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "37d18297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature extraction functions (placeholders)\n",
    "def preprocess_image(image_path):\n",
    "    # Implement image preprocessing and feature extraction\n",
    "    return np.random.rand(num_features_image)\n",
    "\n",
    "def extract_text_features(text_query):\n",
    "    # Implement text feature extraction\n",
    "    return np.random.rand(num_features_text)\n",
    "\n",
    "# Define the model response function\n",
    "def get_model_response(image_path, text_query):\n",
    "    # Extract features\n",
    "    image_features = preprocess_image(image_path)\n",
    "    text_features = extract_text_features(text_query)\n",
    "    \n",
    "    # Ensure the features are 2D arrays\n",
    "    image_features = image_features.reshape(1, -1)  # Convert to 2D array with 1 row\n",
    "    text_features = text_features.reshape(1, -1)  # Convert to 2D array with 1 row\n",
    "    \n",
    "    # Combine features\n",
    "    combined_features = np.concatenate((image_features, text_features), axis=1)\n",
    "    \n",
    "    # Normalize and reduce dimensions\n",
    "    normalized_features = scaler.transform(combined_features)  # Use transform\n",
    "    reduced_features = pca.transform(normalized_features)  # Use transform\n",
    "    \n",
    "    # Classification\n",
    "    prediction = classifier.predict(reduced_features)\n",
    "    return prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f660d379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response: [3]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_path = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\images\\002_0087.jpg\"\n",
    "text_query = 'Whats the color?'\n",
    "response = get_model_response(image_path, text_query)\n",
    "\n",
    "print(f\"Model Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd1bbeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response: [1]\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained text generation model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "def generate_description(features):\n",
    "    # Create a prompt based on features\n",
    "    prompt = f\"Describe the image with features: {features}\"\n",
    "    \n",
    "    # Tokenize the prompt with a large enough max_length\n",
    "    inputs = tokenizer(prompt, return_tensors='pt', max_length=1024, truncation=True)\n",
    "    \n",
    "    # Generate description\n",
    "    outputs = model.generate(\n",
    "        inputs['input_ids'],\n",
    "        attention_mask=inputs.get('attention_mask'),\n",
    "        max_length=150,  # Adjust this to ensure it does not exceed model capacity\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=150,  # This parameter helps control the length of the generated output\n",
    "        do_sample=True  # Optional: Enable sampling to get more varied responses\n",
    "    )\n",
    "    \n",
    "    # Decode the generated text\n",
    "    description = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return description\n",
    "\n",
    "# Example usage\n",
    "image_path = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\images\\002_0087.jpg\"\n",
    "text_query = 'What is in the picture?'\n",
    "response = get_model_response(image_path, text_query)\n",
    "\n",
    "print(f\"Model Response: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff23b825",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 70 features, but LogisticRegression is expecting 1280 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 36\u001b[0m\n\u001b[0;32m     34\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mHP\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mImage Recognitation\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mLincoln_Sparrow_0023_2887691144.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     35\u001b[0m text_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhat is in the image?\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 36\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_model_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[26], line 28\u001b[0m, in \u001b[0;36mget_model_response\u001b[1;34m(image_path, text_query)\u001b[0m\n\u001b[0;32m     25\u001b[0m reduced_features \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mtransform(normalized_features)  \u001b[38;5;66;03m# Use transform\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Classification\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreduced_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_base.py:351\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[38;5;124;03mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    339\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;124;03m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    349\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    350\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 351\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    353\u001b[0m     indices \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(scores \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\linear_model\\_base.py:332\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    329\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    330\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 332\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n\u001b[0;32m    334\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39mreshape(scores, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)) \u001b[38;5;28;01mif\u001b[39;00m scores\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m scores\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 70 features, but LogisticRegression is expecting 1280 features as input."
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import torch\n",
    "\n",
    "# Load pre-trained text generation model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "def generate_description(features):\n",
    "    # Create a prompt based on the type of features or predefined descriptions\n",
    "    prompt = (\n",
    "        \"Given the following image features, describe the image in detail: \"\n",
    "        f\"{features.tolist()}\"\n",
    "    )\n",
    "    \n",
    "    # Tokenize the prompt with a large enough max_length\n",
    "    inputs = tokenizer(prompt, return_tensors='pt', max_length=1024, truncation=True)\n",
    "    \n",
    "    # Generate description\n",
    "    outputs = model.generate(\n",
    "        inputs['input_ids'],\n",
    "        attention_mask=inputs.get('attention_mask'),\n",
    "        max_length=150,  # Adjust this to ensure it does not exceed model capacity\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=150,  # This parameter helps control the length of the generated output\n",
    "        do_sample=True  # Optional: Enable sampling to get more varied responses\n",
    "    )\n",
    "    \n",
    "    # Decode the generated text\n",
    "    description = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return description\n",
    "\n",
    "# Example usage\n",
    "image_path = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\images\\Lincoln_Sparrow_0023_2887691144.jpg\"\n",
    "text_query = 'What is in the image?'\n",
    "response = get_model_response(image_path, text_query)\n",
    "\n",
    "print(f\"Model Response: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c072261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation\\utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Description: a bird with a yellow beak\n"
     ]
    }
   ],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# Load BLIP model and processor\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "def generate_description(image_path):\n",
    "    # Load and process the image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate a description\n",
    "    outputs = model.generate(**inputs)\n",
    "    \n",
    "    # Decode the description\n",
    "    description = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "    return description\n",
    "\n",
    "# Example usage\n",
    "image_path = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\images\\Lincoln_Sparrow_0023_2887691144.jpg\"\n",
    "description = generate_description(image_path)\n",
    "print(f\"Model Description: {description}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4c3616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31699fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
