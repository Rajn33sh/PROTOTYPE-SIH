{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07689d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "694bf31a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'csv_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load CSVs into dataframes\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m dataframes \u001b[38;5;241m=\u001b[39m [pd\u001b[38;5;241m.\u001b[39mread_csv(csv_file) \u001b[38;5;28;01mfor\u001b[39;00m csv_file \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcsv_files\u001b[49m]\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Example: Viewing the first few rows of the first dataframe\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataframes[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mhead())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'csv_files' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSVs into dataframes\n",
    "dataframes = [pd.read_csv(csv_file) for csv_file in csv_files]\n",
    "\n",
    "# Example: Viewing the first few rows of the first dataframe\n",
    "print(dataframes[0].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c337a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Directory where the extracted images are stored\n",
    "extract_folder = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\extracted_data\"\n",
    "\n",
    "# Target directory to save processed images\n",
    "processed_dir = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\processed_images\"\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each subdirectory in the extract_folder\n",
    "for subdir in os.listdir(extract_folder):\n",
    "    subdir_path = os.path.join(extract_folder, subdir)\n",
    "\n",
    "    # Process only directories\n",
    "    if os.path.isdir(subdir_path):\n",
    "        for img_name in os.listdir(subdir_path):\n",
    "            img_path = os.path.join(subdir_path, img_name)\n",
    "\n",
    "            # Only process files\n",
    "            if os.path.isfile(img_path):\n",
    "                try:\n",
    "                    with Image.open(img_path) as img:\n",
    "                        # Example preprocessing: resizing the image to (224, 224)\n",
    "                        img_resized = img.resize((224, 224))\n",
    "                        # Save the preprocessed image\n",
    "                        img_resized.save(os.path.join(processed_dir, img_name))\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process {img_name}: {e}\")\n",
    "\n",
    "print(\"Image preprocessing complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40d88664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image preprocessing and normalization complete.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Directory where the extracted images are stored\n",
    "extract_folder = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\extracted_data\"\n",
    "\n",
    "# Target directory to save processed images\n",
    "processed_dir = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\processed_images\"\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# Loop through each subdirectory in the extract_folder\n",
    "for subdir in os.listdir(extract_folder):\n",
    "    subdir_path = os.path.join(extract_folder, subdir)\n",
    "\n",
    "    # Process only directories\n",
    "    if os.path.isdir(subdir_path):\n",
    "        for img_name in os.listdir(subdir_path):\n",
    "            img_path = os.path.join(subdir_path, img_name)\n",
    "\n",
    "            # Only process files\n",
    "            if os.path.isfile(img_path):\n",
    "                try:\n",
    "                    with Image.open(img_path) as img:\n",
    "                        # Resize the image to (224, 224)\n",
    "                        img_resized = img.resize((224, 224))\n",
    "                        \n",
    "                        # Convert image to a NumPy array and normalize\n",
    "                        img_array = np.array(img_resized).astype(np.float32) / 255.0\n",
    "                        \n",
    "                        # Convert back to an image\n",
    "                        img_normalized = Image.fromarray((img_array * 255).astype(np.uint8))\n",
    "                        \n",
    "                        # Save the preprocessed image\n",
    "                        img_normalized.save(os.path.join(processed_dir, img_name))\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process {img_name}: {e}\")\n",
    "\n",
    "print(\"Image preprocessing and normalization complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62d13198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Define the directory where the images are processed\n",
    "processed_dir = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\processed_images\"\n",
    "\n",
    "# Directory to save extracted features\n",
    "features_dir = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\features\"\n",
    "os.makedirs(features_dir, exist_ok=True)\n",
    "\n",
    "# Define the image transformation to match the input of ResNet18\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load the pre-trained ResNet18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Function to extract features from an image using the pre-trained model\n",
    "def extract_features(image_path, model, transform):\n",
    "    # Load and transform the image\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    img_tensor = transform(img).unsqueeze(0)  # Add batch dimension\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        features = model(img_tensor)\n",
    "    \n",
    "    return features.squeeze().numpy()  # Remove batch dimension and convert to numpy array\n",
    "\n",
    "# Process each image and extract features\n",
    "for img_name in os.listdir(processed_dir):\n",
    "    img_path = os.path.join(processed_dir, img_name)\n",
    "    \n",
    "    if os.path.isfile(img_path):\n",
    "        try:\n",
    "            features = extract_features(img_path, model, transform)\n",
    "            np.save(os.path.join(features_dir, img_name.replace('.jpg', '.npy')), features)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract features from {img_name}: {e}\")\n",
    "\n",
    "print(\"Feature extraction complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "782abefe",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'questions_responses.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestions_responses.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Extract questions\u001b[39;00m\n\u001b[0;32m     11\u001b[0m queries \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuestion\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1024\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1011\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1012\u001b[0m     dialect,\n\u001b[0;32m   1013\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1020\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1021\u001b[0m )\n\u001b[0;32m   1022\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1024\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:618\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    615\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    617\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 618\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1618\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1615\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1617\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1618\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\parsers\\readers.py:1878\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1876\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1877\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1878\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1889\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'questions_responses.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('questions_responses.csv')\n",
    "\n",
    "# Extract questions\n",
    "queries = df['Question'].values\n",
    "\n",
    "# Tokenization and encoding\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(queries)\n",
    "sequences = tokenizer.texts_to_sequences(queries)\n",
    "\n",
    "# Padding sequences to ensure uniform input size\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Print the results\n",
    "print(\"Tokenized and padded queries:\")\n",
    "print(padded_sequences)\n",
    "\n",
    "# Optionally save tokenizer for later use\n",
    "import pickle\n",
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30b3a9d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'padded_sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m normalized_sequences\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m normalized_sequences \u001b[38;5;241m=\u001b[39m normalize_sequences(\u001b[43mpadded_sequences\u001b[49m)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNormalized tokenized and padded queries:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(normalized_sequences)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'padded_sequences' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming `padded_sequences` is your tokenized and padded text data\n",
    "def normalize_sequences(sequences):\n",
    "    # Convert sequences to numpy array for normalization\n",
    "    sequences_np = np.array(sequences, dtype=float)\n",
    "    \n",
    "    # Initialize the StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    \n",
    "    # Normalize the sequences\n",
    "    normalized_sequences = scaler.fit_transform(sequences_np)\n",
    "    \n",
    "    return normalized_sequences\n",
    "\n",
    "# Example usage\n",
    "normalized_sequences = normalize_sequences(padded_sequences)\n",
    "print(\"Normalized tokenized and padded queries:\")\n",
    "print(normalized_sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6bd22b04",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'padded_sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m embedding_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m  \u001b[38;5;66;03m# Dimension of embedding space\u001b[39;00m\n\u001b[0;32m      8\u001b[0m lstm_units \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m  \u001b[38;5;66;03m# Number of LSTM units\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m input_length \u001b[38;5;241m=\u001b[39m \u001b[43mpadded_sequences\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Length of padded sequences\u001b[39;00m\n\u001b[0;32m     10\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m     \u001b[38;5;66;03m# Number of classes for classification (adjust this as needed)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Define the model\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'padded_sequences' is not defined"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# Parameters\n",
    "vocab_size = 10000  # Size of the tokenizer vocabulary\n",
    "embedding_dim = 128  # Dimension of embedding space\n",
    "lstm_units = 64  # Number of LSTM units\n",
    "input_length = padded_sequences.shape[1]  # Length of padded sequences\n",
    "num_classes = 10     # Number of classes for classification (adjust this as needed)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_length),\n",
    "    LSTM(lstm_units, return_sequences=False),\n",
    "    Dense(lstm_units, activation='relu')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Fit the model (for demonstration, you would need proper training data and labels)\n",
    "# model.fit(padded_sequences, labels, epochs=10, batch_size=32)\n",
    "\n",
    "# Extract features\n",
    "text_features = model.predict(padded_sequences)\n",
    "print(\"Extracted features:\")\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e922f955",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[-1.9939196e+00 -8.4555626e-01 -2.3387229e+00 -4.4125257e+00\n -3.1227643e+00  2.4605188e+00  1.0050197e+00 -6.3310319e-01\n  7.2966111e-01  3.8137548e+00  7.4052100e+00  3.9826109e+00\n  2.4990387e+00  6.6070523e+00  3.0617247e+00  8.6111641e+00\n  5.5946555e+00  4.8946190e+00  3.9981496e+00  7.3557539e+00\n  1.0201323e+01  4.5370078e+00  3.3402932e+00  6.7482436e-01\n  3.9036582e+00  2.3915422e+00  6.6188736e+00  3.5156238e+00\n -8.9494079e-02 -1.3304713e+00  3.3425145e+00  6.2310925e+00\n  4.9661999e+00  1.2399760e+00  1.9878036e+00  3.7653320e+00\n  4.0677128e+00  2.1187885e+00  5.5738254e+00  8.5208273e+00\n  1.0867703e+01  8.4217033e+00  1.0075059e+01  9.4817476e+00\n  7.7223659e+00  7.3388678e-01  8.7565298e+00  7.2358384e+00\n  2.9037430e+00  1.9532803e+00  1.7272254e+00 -1.6512737e+00\n  4.5064087e+00  5.0155101e+00  5.4110885e+00  6.6788139e+00\n  1.5066624e+00  5.3771424e+00  6.7508063e+00  1.0033520e+01\n  6.9514098e+00  2.8652630e+00  4.7446756e+00  5.5874243e+00\n  3.8475680e+00  3.8761005e+00  5.2529464e+00  3.1687710e+00\n  4.3750577e+00  3.2310052e+00  8.9103985e+00  6.5216680e+00\n  5.6162934e+00  5.9037981e+00  5.8048382e+00  3.1786039e+00\n  4.2669182e+00  9.0278254e+00  4.1721458e+00  7.2989182e+00\n  9.6852839e-01  3.0347674e+00  3.8586638e+00  1.6463610e+00\n  2.2830911e+00  6.1954489e+00  3.5301623e+00  2.7953377e-01\n  2.6489143e+00  2.5670140e+00  8.1152719e-01  7.3373270e+00\n  7.8371921e+00  3.4585860e+00  8.4376678e+00  8.3638973e+00\n  7.7846527e-01 -1.2664485e+00  7.4515849e-01 -7.5644273e-01\n -2.2307181e+00 -1.7457467e-01  2.1761351e+00  4.8446140e-01\n  3.1074655e+00  6.0059279e-01 -6.5165025e-01 -2.5512958e+00\n -8.8718563e-01 -2.1826322e+00  1.7251753e+00  4.6996584e+00\n  2.3691936e+00  6.9662805e+00  9.5274019e+00  1.1929747e+00\n  2.4891579e+00  5.5882260e-02  1.6568668e+00  5.6055446e+00\n  8.8918390e+00 -4.5498908e-01 -1.3574302e+00  3.7390945e+00\n  6.5604582e+00  3.2170756e+00  5.6376386e+00  1.0419971e+00\n  4.7341127e+00  4.8137250e+00 -2.6916981e+00  7.7429538e+00\n  7.8665709e+00  1.0519323e+01  4.9256606e+00  7.3532391e+00\n  2.6428401e+00  1.6886519e+00  6.5847349e+00  2.1072991e+00\n  3.6216772e+00  4.9611278e+00  4.7204418e+00  1.6685016e+00\n  3.4995489e+00  4.7224755e+00  2.3427837e+00  2.5745791e-01\n -2.6114583e+00 -3.1668241e+00  2.1277027e+00  1.4327852e+00\n -5.6709492e-01 -3.5540013e+00 -3.0599198e+00 -3.2734759e+00\n  7.3375076e-01 -5.2814841e-01 -1.5556542e+00 -1.2613004e-01\n -1.2115685e+00  7.5378102e-01  2.8165238e+00  1.2498591e+00\n  2.0162833e+00  5.1570529e-01  3.9573569e+00  3.5442848e+00\n  4.3086571e-01 -1.7087462e+00 -2.7787528e+00  1.5906227e+00\n  3.0214328e-01  2.4765434e+00 -1.5969223e+00 -1.5817001e+00\n  1.3352757e+00 -1.2393396e+00 -5.2410358e-01 -5.6556833e-01\n -8.5191166e-01 -1.7592551e+00 -5.6755316e-01 -1.2279451e+00\n -1.9910874e+00 -1.9157721e+00 -1.7433007e+00 -1.3250533e+00\n -1.9854438e+00  8.6911574e-02 -3.7149105e+00 -1.1975091e+00\n -1.7167119e+00 -2.2598038e+00 -5.5941691e+00 -2.7077627e+00\n -4.1545615e+00 -2.1202488e+00 -1.7225448e+00 -4.0412421e+00\n -1.1250272e+00 -3.3952062e+00 -3.4118419e+00 -2.8377070e+00\n -3.6249044e+00 -6.7083192e-01  1.9558273e-02 -1.5541300e+00\n  4.7885880e-01 -8.1789303e-01 -7.1701407e-01 -5.5754608e-01\n -2.4144695e+00 -9.8358876e-01 -4.8660883e-01 -7.9929374e-02\n -1.5017039e+00 -2.4706776e+00 -6.6743004e-01 -2.2169480e+00\n -1.4473389e+00 -6.9838357e-01 -2.2664576e+00  2.1026288e-01\n  1.0148997e+00 -7.1231210e-01 -3.6008015e+00  9.4646432e-02\n -2.1625514e+00 -3.5171890e+00 -1.9700810e-01 -2.5839812e-01\n -7.4893731e-01 -1.9394008e+00 -8.2786566e-01 -1.3049188e+00\n  7.0155549e-01 -4.3063417e-01  2.1375749e+00  1.2233374e+00\n  1.6591743e+00  1.2661316e+00 -1.1844991e+00 -2.6115041e+00\n -8.0806297e-01 -4.4624934e+00 -6.8982852e-01 -4.1708079e-01\n -3.0806515e-01 -2.7531905e+00 -1.5824459e+00 -2.0501788e+00\n -3.1854236e+00  3.2954324e-02 -2.3089345e+00  6.5503366e-02\n -5.7536447e-01 -2.5155590e+00 -2.9812703e+00 -1.4180932e+00\n -2.8801365e+00 -3.0076113e+00 -1.6988516e+00  1.5266622e+00\n -1.6596088e+00 -2.4867871e+00 -2.1491358e+00 -1.9834050e+00\n -1.0885596e+00  4.0927725e+00  2.5457280e+00  4.5667710e+00\n  5.9290204e+00  2.4298706e+00  3.1522512e+00  4.7987407e-01\n -1.1247426e+00  5.8169866e+00  5.3607926e+00  1.8440914e+00\n  6.8423042e+00  1.1800848e+00  1.7121195e+00 -1.2874779e+00\n -8.0277205e-01  1.7404926e+00  2.3696713e+00  2.0573771e+00\n  2.6922641e+00  8.2295138e-01  6.5198326e-01 -4.9442706e-01\n -3.3947769e-01 -1.8832749e-01  1.7885238e-02  3.0367968e+00\n -3.1570578e+00  1.8169973e+00  5.8787823e+00  5.3247957e+00\n  2.8705604e+00  3.9319816e+00  3.3237445e+00  6.0811296e+00\n  2.3405759e+00  2.9410131e+00  5.4096942e+00  5.3457804e+00\n  8.0758257e+00  8.1109161e+00  9.9027224e+00  1.0579746e+01\n  9.4773026e+00  1.2077886e+01  4.4437132e+00  1.1815689e+01\n  1.0303993e+01  1.0781896e+01  9.3057222e+00  1.3221822e+01\n  1.0846439e+01  6.6095090e+00  9.3018990e+00  4.3087707e+00\n  7.6564927e+00  5.0607743e+00  9.0874176e+00  6.8060599e-02\n  2.1572320e+00 -1.0457115e+00  3.1545444e+00  4.8331895e+00\n -2.3084815e+00  1.0312502e+00  1.0740141e+00  7.0089221e+00\n  5.9370713e+00  3.7341917e+00 -1.5413933e+00 -1.7523152e+00\n -5.0834972e-01  2.9945824e-01  1.6744512e+00  6.4430064e-01\n -3.5860856e+00  5.8941711e-02 -1.4088713e+00 -6.4012885e-01\n  9.0323180e-01  2.0193706e+00  3.8540633e+00 -2.0432128e-01\n  1.3015996e+00  2.6000946e+00 -6.1039537e-02  1.2747084e+00\n  6.9036179e+00  6.6460085e+00  3.1058207e+00  6.2810525e-02\n  1.5141369e+00 -2.2700302e-01  1.9197257e+00  1.3198303e+00\n  1.7928829e+00  3.6545184e-01  1.2819371e+00  1.9821123e+00\n  1.9112813e+00  3.3247540e+00  6.4848938e+00  7.1964035e+00\n  9.9480635e-01  3.5326545e+00  4.2690568e+00  2.9398377e+00\n  3.4160173e+00  5.6300731e+00  4.3875418e+00  3.9426222e+00\n  6.8264647e+00  3.0283000e+00  5.6899810e+00  3.6465485e+00\n  5.3480544e+00 -8.7738413e-01 -9.3249750e-01  2.7360790e+00\n -9.3264443e-01  2.2375236e-01  4.9510865e+00 -4.3357611e-01\n -3.3101764e-01 -2.9524820e+00 -5.9774041e-01  4.4128714e+00\n  1.5016766e+00  1.5389246e+00 -6.0793204e+00  7.4209386e-01\n -1.4186817e+00 -1.9073629e+00 -2.2681305e+00 -2.2757940e+00\n -3.1571476e+00 -4.4146566e+00 -3.1201148e+00 -3.4358411e+00\n -4.4541459e+00 -3.1045132e+00  3.3899417e+00 -2.1167917e+00\n -6.4098293e-01 -3.7413187e+00 -1.3702608e+00 -3.0608354e+00\n  2.3353963e+00 -5.6699014e+00  1.7583358e-01  1.9828567e-01\n -2.9101982e+00  1.1352407e+00 -4.7906899e+00 -2.4422245e+00\n -3.7268856e+00 -1.3642068e+00 -3.3467047e+00 -1.5671648e+00\n  3.1940751e+00 -2.1344917e+00 -2.4742734e+00 -7.8238082e-01\n -1.1137865e+00 -4.5033207e+00 -1.0750744e+00 -3.3606782e+00\n -4.6390862e+00 -4.6629558e+00 -1.0435282e+00  6.8380398e-01\n -8.1918645e-01 -1.7860026e+00 -2.7591531e+00 -2.1983519e+00\n -2.9404702e+00 -3.8765192e-02 -1.5955325e+00 -3.1969955e+00\n  1.6858904e+00 -3.0518668e+00 -1.9534476e+00  2.6471035e+00\n  2.1878254e+00 -3.1110954e+00 -4.3604870e+00 -9.1205138e-01\n  5.8819227e+00 -3.5111566e+00  1.5901314e+00  1.0050193e-01\n -1.4623649e+00  1.0232396e+00  2.1569314e+00  1.6823697e+00\n  2.8733897e-01 -1.0278692e+00 -1.3929478e+00 -4.2308397e+00\n -2.6608777e+00 -1.9744239e+00 -7.7947503e-01 -3.8107831e+00\n  4.5755213e-01  5.5139220e-01 -2.4862511e+00 -1.7247492e+00\n -4.7776618e+00 -1.3194066e+00 -1.4192213e+00 -1.8064376e+00\n -2.7020876e+00 -2.0972002e+00 -1.5282948e+00 -3.4230447e+00\n -1.5266711e+00 -3.0904489e+00 -3.3789289e+00 -2.4019203e-01\n -1.1913464e+00  3.6393855e+00 -1.1161515e+00 -1.2663022e+00\n -3.5577862e+00 -2.1116648e+00  3.3753699e-01 -6.1491852e+00\n -5.3795648e+00 -3.3388252e+00 -3.7377899e+00 -1.7751285e+00\n -5.5604786e-01  2.0576441e+00 -9.3948841e-01 -1.1986356e+00\n -2.0895677e+00  5.3960162e-01  2.1659747e-01 -2.4987733e+00\n -2.9863241e+00 -2.5183718e+00 -3.3592846e+00 -6.1289887e+00\n -6.4854372e-01 -1.8148730e+00  5.6223881e-01 -2.1178700e-01\n -1.5139343e+00 -1.2061387e+00 -1.5624262e+00 -1.0178812e+00\n -4.4890985e+00 -4.4499154e+00  2.8653342e-01  2.0391898e+00\n -1.6920041e-01  5.2400798e-01 -4.8709536e+00 -2.7823212e+00\n -4.3280678e+00 -2.2148230e+00 -4.3944421e+00 -3.8208742e+00\n -3.4446666e+00 -1.7222164e+00 -2.7819488e+00 -2.9122450e+00\n -3.6202753e+00  6.0598767e-01 -3.6765614e+00 -4.0140424e+00\n -3.3209579e+00 -1.1005994e+00 -2.7643225e-01 -5.6338224e+00\n -9.6630239e-01 -1.8759115e+00 -2.3521819e+00 -1.7863389e+00\n -1.4039406e+00 -2.1633394e+00 -3.1201656e+00 -2.7216187e+00\n -2.7281024e+00 -2.1830683e+00 -6.1142459e+00 -3.0204833e+00\n -5.4280454e-01 -1.7481856e+00  1.1813291e+00 -9.1956902e-01\n -3.5288618e+00 -2.9620578e+00 -1.0475310e-01  2.1381934e+00\n -4.8430347e+00 -2.7959943e+00 -1.5639552e+00 -1.2189798e+00\n -4.3197414e-01 -1.3138995e+00 -1.4741604e+00 -4.2477255e+00\n  5.3962862e-01 -3.1513679e+00  1.7850728e+00 -5.0134654e+00\n -1.8334749e+00 -7.0515186e-01 -5.7970750e-01 -3.9227436e+00\n -2.5290163e+00 -2.2264233e+00 -1.5183083e+00 -1.6221555e+00\n -4.2904112e-01 -3.6798215e+00 -3.5050306e+00  8.7500578e-01\n -1.5873286e+00 -4.3919539e+00 -2.6445956e+00 -1.5879468e+00\n -5.9405959e-01 -1.3002276e+00 -2.4275298e+00 -4.4333611e+00\n  3.5615790e+00 -2.6419458e+00 -3.4496155e+00  6.9729462e+00\n  3.6354921e+00 -1.9484106e+00  1.8434908e+00 -1.8927895e+00\n -1.5452069e+00  2.1999696e-01 -6.9028229e-01 -4.2414379e+00\n  2.2799165e+00 -3.4274008e+00 -1.6988693e+00 -4.2199540e+00\n -2.0603168e+00 -3.4022100e+00 -2.7387195e+00 -2.5910950e+00\n  2.2176220e+00 -1.3050113e+00  6.1989598e+00 -2.7798843e+00\n -2.1139958e+00 -2.0281465e+00 -2.9809322e+00  4.6724358e+00\n -3.4105651e+00 -4.4057932e+00  5.4659671e-01 -2.7437749e+00\n -3.0223627e+00 -2.9550862e+00  9.0281449e-02 -2.5569649e+00\n  5.8744317e-01  9.2155226e-02 -1.6554773e+00 -3.0282156e+00\n -4.5606771e-01 -3.6633959e-01 -9.2947960e-01 -2.5414097e+00\n -2.4759457e+00 -4.2071252e+00 -6.0801868e+00  2.7586418e-01\n  4.3230224e+00 -1.1128653e+00 -3.1637990e+00  7.8838623e-01\n -4.0510983e+00 -6.5385258e-01 -5.3992789e-02 -2.4814074e+00\n  1.8379760e-01 -2.1323807e+00 -4.1285176e+00 -4.3440074e-01\n -3.1511481e+00 -1.7326244e+00 -2.3155454e-01  4.7465198e-02\n -9.3367672e-01 -4.6448650e+00 -2.7970572e+00 -2.6494071e+00\n -3.4328526e-01 -4.5774727e+00 -9.8821568e-01 -7.3234636e-01\n -4.1877298e+00 -3.2186248e+00 -4.0624938e+00 -2.1906693e+00\n  5.4304701e-01 -2.9978611e+00  3.0431221e+00 -2.3191891e+00\n -6.8931051e-02  8.3938351e+00 -1.8880205e+00 -2.5566232e+00\n -8.3858466e-01 -2.5671110e+00 -4.3396142e-01 -3.1276128e+00\n -3.4475198e+00 -3.2465963e+00 -4.0633569e+00 -7.5113873e+00\n -3.5836246e+00  4.9751747e-02 -1.7953967e+00 -2.3901623e-01\n  1.8466169e+00  4.0622940e+00 -5.3129244e+00 -1.9117218e+00\n  2.6734695e+00 -3.6774833e+00 -5.1124830e+00 -2.7643316e+00\n  1.3815658e+00 -4.1313620e+00  2.7264378e+00 -1.5558192e-01\n -4.0845335e-02 -1.1757740e+00 -5.0650792e+00 -1.8161966e+00\n -5.3423268e-01 -1.2910435e+00  7.2475994e-01  5.9407568e-01\n -1.2285579e+00 -2.4835703e+00 -1.6285999e+00  2.6052395e-01\n  1.7143499e+00 -3.5942452e+00 -2.8884799e+00 -4.0051246e+00\n -3.2196639e+00 -1.8295245e+00  5.1223326e-01 -7.0626163e-01\n -3.9330454e+00 -3.1770578e-01 -2.2280674e+00 -6.0538025e+00\n  1.1058289e+00 -5.1201153e+00  1.3087488e+00 -3.9981735e-01\n -3.1392620e+00  3.9892993e+00 -3.7718573e+00 -2.5819662e+00\n -5.2637277e+00 -1.2397423e+00  1.1685716e+00 -2.7981911e+00\n -4.6840501e+00 -3.6548841e+00 -3.7537527e+00  3.1288113e-02\n -1.7078738e+00 -5.3499022e+00 -3.5428674e+00 -2.9186103e+00\n -1.3180321e+00  5.4340529e+00 -4.7752638e+00 -2.3788280e+00\n -1.6559899e-02 -9.7215313e-01 -7.3781693e-01 -6.8629801e-01\n -9.7874522e-01 -7.6974779e-01  7.3844308e-01 -4.0834708e+00\n -3.9010470e+00 -1.5001590e+00 -3.8788476e+00 -2.1746492e+00\n -9.8555547e-01 -5.1238406e-01 -1.5875995e+00 -1.0906308e+00\n -7.6636887e-01  1.2533933e+00  7.4113029e-01 -2.0195348e+00\n  1.6032138e+00 -1.6825759e+00  8.5868955e-01 -9.5201534e-01\n -2.3351102e+00  3.3393745e+00 -2.1054888e+00 -2.9180994e+00\n -2.1264777e+00 -2.0685399e+00 -5.3342420e-01  6.3026518e-01\n  1.3690025e+00 -3.0918221e+00 -4.7712436e+00  1.8220634e+00\n -2.5889032e+00 -2.7938271e+00 -3.4848619e+00  5.0482005e-01\n  2.8663638e+00 -2.9479389e+00 -3.7755225e+00  3.8571517e+00\n  1.1357422e+00 -1.1147201e+00 -1.1663015e+00 -2.7979705e+00\n -5.2766542e+00 -3.0663731e+00 -2.7378182e+00  1.2201118e-01\n -7.7789706e-01 -2.7592998e+00 -1.9375327e+00  2.7111340e-02\n  2.3546192e-01  1.5606791e-01 -5.5223856e+00 -2.1874368e+00\n -8.6189806e-01  1.2606708e+00 -5.2966125e-02  5.1558309e+00\n -5.0453824e-01 -4.3313036e+00  1.7646787e+00 -2.5486209e+00\n -3.7736020e+00 -1.9599577e+00 -2.0471752e+00 -2.5638576e+00\n -1.0092226e+00  2.4811065e+00 -2.6492572e+00 -3.0892034e+00\n  2.4489703e+00 -8.6058891e-01 -6.4061254e-01 -6.2572956e+00\n -3.1980715e+00 -1.4776329e+00 -2.1374648e+00  3.4797621e+00\n -7.4177778e-01 -1.2193381e+00 -1.7345785e+00  5.1132063e-03\n  1.4253308e+00  9.5127359e-02 -3.2582004e+00 -1.4071333e+00\n -2.7519395e+00  1.8764343e+00 -6.8902677e-01 -3.7619495e+00\n -1.4388189e+00 -1.2148277e+00 -2.6104827e+00  1.9347938e+00\n  2.7001092e-01 -1.3980728e+00 -4.4715662e+00  7.8806120e-01\n -5.4270196e+00 -1.0676922e+00 -4.2044091e+00 -5.2969885e-01\n -6.3372898e+00 -2.8104205e+00  3.3833361e+00 -2.5058007e+00\n -2.3970687e+00 -5.6405592e+00 -2.9094143e+00 -3.1877863e-01\n -1.7371469e+00 -2.7359350e+00 -3.6501079e+00 -1.9430411e+00\n -7.9828948e-02 -3.9232507e+00 -3.2717352e+00  1.8323456e+00\n -3.0945141e+00 -3.0686839e+00 -4.8254991e+00 -6.4368403e-01\n -2.9707170e+00 -4.6318336e+00 -2.0313132e+00  6.5425283e-01\n -2.4160602e+00 -2.3621473e+00 -4.5858727e+00  6.1263674e-01\n -1.0501320e+00 -1.4476343e+00 -1.0720382e+00 -3.9596753e+00\n -3.7776830e+00 -1.4383219e+00 -3.0732677e+00 -2.1022837e+00\n -1.9204046e+00 -2.9713254e+00 -1.3523822e+00  8.9885797e-03\n -4.2236562e+00 -2.5426385e+00 -8.0880290e-01 -2.6704931e+00\n  3.0349474e+00 -4.8217974e+00 -2.1830723e+00 -5.4794043e-02\n -2.3846807e+00 -2.0510867e+00  2.4600139e+00 -2.9052076e+00\n  6.3329945e+00 -9.6087176e-01 -7.6369262e-01 -1.7106798e+00\n -2.4767666e+00 -3.9139633e+00 -1.9978526e+00  1.5089788e+00\n -2.4276683e+00 -1.1621584e+00 -3.9304488e+00 -1.2055030e+00\n  5.3539997e-01 -1.7801806e+00 -2.8666351e+00 -6.8244755e-01\n  1.0260215e+00 -4.9348646e-01 -1.3140255e-01 -1.6667511e+00\n -2.6473124e+00 -3.8331764e+00 -1.8891780e+00 -2.5004699e+00\n -1.5798080e+00 -8.5195875e-01 -2.5042160e+00 -1.2804494e+00\n -1.2459463e+00 -1.1208673e+00 -2.0905542e+00 -9.4923958e-02\n  1.1930703e+00  8.5317856e-01  4.4032688e+00  4.0019350e+00\n  4.1523632e-01  7.3572546e-01  1.0540587e+00 -2.5120968e-01\n  9.2998421e-01  1.7904966e+00 -1.3486177e+00  8.0633914e-01\n  4.8312372e-01 -8.5601318e-01 -1.2547373e+00 -2.7571945e+00\n -6.8049145e-01 -2.3599148e+00 -1.3818531e-01 -2.5527167e+00\n -1.2411634e+00 -7.4724537e-01 -1.9643520e+00 -3.3836618e-01\n -1.1120626e+00 -1.7412913e+00  3.2453523e+00 -1.7753679e+00\n  1.9378021e+00 -2.7521628e-01 -1.5307586e+00  1.5053518e+00\n -9.9025470e-01 -1.1675348e+00 -1.0547174e+00  8.1667864e-01\n  3.9220229e-01 -2.0835922e+00 -2.5169868e+00 -4.1935763e+00\n -9.7508198e-01  5.5674133e+00  5.8121023e+00  1.3295478e+00\n  3.3260772e+00  5.0068846e+00  3.1887755e+00  5.1851544e+00\n  2.1173346e+00  1.7794693e+00  6.2960691e+00  5.1778574e+00\n  3.6616595e+00  2.4098606e+00  4.4120312e+00 -9.2818856e-01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming `query_features` is your text feature matrix\u001b[39;00m\n\u001b[0;32m      5\u001b[0m scaler \u001b[38;5;241m=\u001b[39m StandardScaler()\n\u001b[1;32m----> 6\u001b[0m normalized_query_features \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_set_output.py:273\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 273\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    276\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    277\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    278\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    279\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:1061\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m   1046\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1047\u001b[0m             (\n\u001b[0;32m   1048\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1056\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1057\u001b[0m         )\n\u001b[0;32m   1059\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1060\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1063\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\preprocessing\\_data.py:876\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    874\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 876\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\preprocessing\\_data.py:912\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[0;32m    881\u001b[0m \n\u001b[0;32m    882\u001b[0m \u001b[38;5;124;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[38;5;124;03m    Fitted scaler.\u001b[39;00m\n\u001b[0;32m    910\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    911\u001b[0m first_call \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 912\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    913\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    914\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    919\u001b[0m n_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\validation.py:989\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    982\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    983\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    984\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    988\u001b[0m             )\n\u001b[1;32m--> 989\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    992\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    994\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    995\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[-1.9939196e+00 -8.4555626e-01 -2.3387229e+00 -4.4125257e+00\n -3.1227643e+00  2.4605188e+00  1.0050197e+00 -6.3310319e-01\n  7.2966111e-01  3.8137548e+00  7.4052100e+00  3.9826109e+00\n  2.4990387e+00  6.6070523e+00  3.0617247e+00  8.6111641e+00\n  5.5946555e+00  4.8946190e+00  3.9981496e+00  7.3557539e+00\n  1.0201323e+01  4.5370078e+00  3.3402932e+00  6.7482436e-01\n  3.9036582e+00  2.3915422e+00  6.6188736e+00  3.5156238e+00\n -8.9494079e-02 -1.3304713e+00  3.3425145e+00  6.2310925e+00\n  4.9661999e+00  1.2399760e+00  1.9878036e+00  3.7653320e+00\n  4.0677128e+00  2.1187885e+00  5.5738254e+00  8.5208273e+00\n  1.0867703e+01  8.4217033e+00  1.0075059e+01  9.4817476e+00\n  7.7223659e+00  7.3388678e-01  8.7565298e+00  7.2358384e+00\n  2.9037430e+00  1.9532803e+00  1.7272254e+00 -1.6512737e+00\n  4.5064087e+00  5.0155101e+00  5.4110885e+00  6.6788139e+00\n  1.5066624e+00  5.3771424e+00  6.7508063e+00  1.0033520e+01\n  6.9514098e+00  2.8652630e+00  4.7446756e+00  5.5874243e+00\n  3.8475680e+00  3.8761005e+00  5.2529464e+00  3.1687710e+00\n  4.3750577e+00  3.2310052e+00  8.9103985e+00  6.5216680e+00\n  5.6162934e+00  5.9037981e+00  5.8048382e+00  3.1786039e+00\n  4.2669182e+00  9.0278254e+00  4.1721458e+00  7.2989182e+00\n  9.6852839e-01  3.0347674e+00  3.8586638e+00  1.6463610e+00\n  2.2830911e+00  6.1954489e+00  3.5301623e+00  2.7953377e-01\n  2.6489143e+00  2.5670140e+00  8.1152719e-01  7.3373270e+00\n  7.8371921e+00  3.4585860e+00  8.4376678e+00  8.3638973e+00\n  7.7846527e-01 -1.2664485e+00  7.4515849e-01 -7.5644273e-01\n -2.2307181e+00 -1.7457467e-01  2.1761351e+00  4.8446140e-01\n  3.1074655e+00  6.0059279e-01 -6.5165025e-01 -2.5512958e+00\n -8.8718563e-01 -2.1826322e+00  1.7251753e+00  4.6996584e+00\n  2.3691936e+00  6.9662805e+00  9.5274019e+00  1.1929747e+00\n  2.4891579e+00  5.5882260e-02  1.6568668e+00  5.6055446e+00\n  8.8918390e+00 -4.5498908e-01 -1.3574302e+00  3.7390945e+00\n  6.5604582e+00  3.2170756e+00  5.6376386e+00  1.0419971e+00\n  4.7341127e+00  4.8137250e+00 -2.6916981e+00  7.7429538e+00\n  7.8665709e+00  1.0519323e+01  4.9256606e+00  7.3532391e+00\n  2.6428401e+00  1.6886519e+00  6.5847349e+00  2.1072991e+00\n  3.6216772e+00  4.9611278e+00  4.7204418e+00  1.6685016e+00\n  3.4995489e+00  4.7224755e+00  2.3427837e+00  2.5745791e-01\n -2.6114583e+00 -3.1668241e+00  2.1277027e+00  1.4327852e+00\n -5.6709492e-01 -3.5540013e+00 -3.0599198e+00 -3.2734759e+00\n  7.3375076e-01 -5.2814841e-01 -1.5556542e+00 -1.2613004e-01\n -1.2115685e+00  7.5378102e-01  2.8165238e+00  1.2498591e+00\n  2.0162833e+00  5.1570529e-01  3.9573569e+00  3.5442848e+00\n  4.3086571e-01 -1.7087462e+00 -2.7787528e+00  1.5906227e+00\n  3.0214328e-01  2.4765434e+00 -1.5969223e+00 -1.5817001e+00\n  1.3352757e+00 -1.2393396e+00 -5.2410358e-01 -5.6556833e-01\n -8.5191166e-01 -1.7592551e+00 -5.6755316e-01 -1.2279451e+00\n -1.9910874e+00 -1.9157721e+00 -1.7433007e+00 -1.3250533e+00\n -1.9854438e+00  8.6911574e-02 -3.7149105e+00 -1.1975091e+00\n -1.7167119e+00 -2.2598038e+00 -5.5941691e+00 -2.7077627e+00\n -4.1545615e+00 -2.1202488e+00 -1.7225448e+00 -4.0412421e+00\n -1.1250272e+00 -3.3952062e+00 -3.4118419e+00 -2.8377070e+00\n -3.6249044e+00 -6.7083192e-01  1.9558273e-02 -1.5541300e+00\n  4.7885880e-01 -8.1789303e-01 -7.1701407e-01 -5.5754608e-01\n -2.4144695e+00 -9.8358876e-01 -4.8660883e-01 -7.9929374e-02\n -1.5017039e+00 -2.4706776e+00 -6.6743004e-01 -2.2169480e+00\n -1.4473389e+00 -6.9838357e-01 -2.2664576e+00  2.1026288e-01\n  1.0148997e+00 -7.1231210e-01 -3.6008015e+00  9.4646432e-02\n -2.1625514e+00 -3.5171890e+00 -1.9700810e-01 -2.5839812e-01\n -7.4893731e-01 -1.9394008e+00 -8.2786566e-01 -1.3049188e+00\n  7.0155549e-01 -4.3063417e-01  2.1375749e+00  1.2233374e+00\n  1.6591743e+00  1.2661316e+00 -1.1844991e+00 -2.6115041e+00\n -8.0806297e-01 -4.4624934e+00 -6.8982852e-01 -4.1708079e-01\n -3.0806515e-01 -2.7531905e+00 -1.5824459e+00 -2.0501788e+00\n -3.1854236e+00  3.2954324e-02 -2.3089345e+00  6.5503366e-02\n -5.7536447e-01 -2.5155590e+00 -2.9812703e+00 -1.4180932e+00\n -2.8801365e+00 -3.0076113e+00 -1.6988516e+00  1.5266622e+00\n -1.6596088e+00 -2.4867871e+00 -2.1491358e+00 -1.9834050e+00\n -1.0885596e+00  4.0927725e+00  2.5457280e+00  4.5667710e+00\n  5.9290204e+00  2.4298706e+00  3.1522512e+00  4.7987407e-01\n -1.1247426e+00  5.8169866e+00  5.3607926e+00  1.8440914e+00\n  6.8423042e+00  1.1800848e+00  1.7121195e+00 -1.2874779e+00\n -8.0277205e-01  1.7404926e+00  2.3696713e+00  2.0573771e+00\n  2.6922641e+00  8.2295138e-01  6.5198326e-01 -4.9442706e-01\n -3.3947769e-01 -1.8832749e-01  1.7885238e-02  3.0367968e+00\n -3.1570578e+00  1.8169973e+00  5.8787823e+00  5.3247957e+00\n  2.8705604e+00  3.9319816e+00  3.3237445e+00  6.0811296e+00\n  2.3405759e+00  2.9410131e+00  5.4096942e+00  5.3457804e+00\n  8.0758257e+00  8.1109161e+00  9.9027224e+00  1.0579746e+01\n  9.4773026e+00  1.2077886e+01  4.4437132e+00  1.1815689e+01\n  1.0303993e+01  1.0781896e+01  9.3057222e+00  1.3221822e+01\n  1.0846439e+01  6.6095090e+00  9.3018990e+00  4.3087707e+00\n  7.6564927e+00  5.0607743e+00  9.0874176e+00  6.8060599e-02\n  2.1572320e+00 -1.0457115e+00  3.1545444e+00  4.8331895e+00\n -2.3084815e+00  1.0312502e+00  1.0740141e+00  7.0089221e+00\n  5.9370713e+00  3.7341917e+00 -1.5413933e+00 -1.7523152e+00\n -5.0834972e-01  2.9945824e-01  1.6744512e+00  6.4430064e-01\n -3.5860856e+00  5.8941711e-02 -1.4088713e+00 -6.4012885e-01\n  9.0323180e-01  2.0193706e+00  3.8540633e+00 -2.0432128e-01\n  1.3015996e+00  2.6000946e+00 -6.1039537e-02  1.2747084e+00\n  6.9036179e+00  6.6460085e+00  3.1058207e+00  6.2810525e-02\n  1.5141369e+00 -2.2700302e-01  1.9197257e+00  1.3198303e+00\n  1.7928829e+00  3.6545184e-01  1.2819371e+00  1.9821123e+00\n  1.9112813e+00  3.3247540e+00  6.4848938e+00  7.1964035e+00\n  9.9480635e-01  3.5326545e+00  4.2690568e+00  2.9398377e+00\n  3.4160173e+00  5.6300731e+00  4.3875418e+00  3.9426222e+00\n  6.8264647e+00  3.0283000e+00  5.6899810e+00  3.6465485e+00\n  5.3480544e+00 -8.7738413e-01 -9.3249750e-01  2.7360790e+00\n -9.3264443e-01  2.2375236e-01  4.9510865e+00 -4.3357611e-01\n -3.3101764e-01 -2.9524820e+00 -5.9774041e-01  4.4128714e+00\n  1.5016766e+00  1.5389246e+00 -6.0793204e+00  7.4209386e-01\n -1.4186817e+00 -1.9073629e+00 -2.2681305e+00 -2.2757940e+00\n -3.1571476e+00 -4.4146566e+00 -3.1201148e+00 -3.4358411e+00\n -4.4541459e+00 -3.1045132e+00  3.3899417e+00 -2.1167917e+00\n -6.4098293e-01 -3.7413187e+00 -1.3702608e+00 -3.0608354e+00\n  2.3353963e+00 -5.6699014e+00  1.7583358e-01  1.9828567e-01\n -2.9101982e+00  1.1352407e+00 -4.7906899e+00 -2.4422245e+00\n -3.7268856e+00 -1.3642068e+00 -3.3467047e+00 -1.5671648e+00\n  3.1940751e+00 -2.1344917e+00 -2.4742734e+00 -7.8238082e-01\n -1.1137865e+00 -4.5033207e+00 -1.0750744e+00 -3.3606782e+00\n -4.6390862e+00 -4.6629558e+00 -1.0435282e+00  6.8380398e-01\n -8.1918645e-01 -1.7860026e+00 -2.7591531e+00 -2.1983519e+00\n -2.9404702e+00 -3.8765192e-02 -1.5955325e+00 -3.1969955e+00\n  1.6858904e+00 -3.0518668e+00 -1.9534476e+00  2.6471035e+00\n  2.1878254e+00 -3.1110954e+00 -4.3604870e+00 -9.1205138e-01\n  5.8819227e+00 -3.5111566e+00  1.5901314e+00  1.0050193e-01\n -1.4623649e+00  1.0232396e+00  2.1569314e+00  1.6823697e+00\n  2.8733897e-01 -1.0278692e+00 -1.3929478e+00 -4.2308397e+00\n -2.6608777e+00 -1.9744239e+00 -7.7947503e-01 -3.8107831e+00\n  4.5755213e-01  5.5139220e-01 -2.4862511e+00 -1.7247492e+00\n -4.7776618e+00 -1.3194066e+00 -1.4192213e+00 -1.8064376e+00\n -2.7020876e+00 -2.0972002e+00 -1.5282948e+00 -3.4230447e+00\n -1.5266711e+00 -3.0904489e+00 -3.3789289e+00 -2.4019203e-01\n -1.1913464e+00  3.6393855e+00 -1.1161515e+00 -1.2663022e+00\n -3.5577862e+00 -2.1116648e+00  3.3753699e-01 -6.1491852e+00\n -5.3795648e+00 -3.3388252e+00 -3.7377899e+00 -1.7751285e+00\n -5.5604786e-01  2.0576441e+00 -9.3948841e-01 -1.1986356e+00\n -2.0895677e+00  5.3960162e-01  2.1659747e-01 -2.4987733e+00\n -2.9863241e+00 -2.5183718e+00 -3.3592846e+00 -6.1289887e+00\n -6.4854372e-01 -1.8148730e+00  5.6223881e-01 -2.1178700e-01\n -1.5139343e+00 -1.2061387e+00 -1.5624262e+00 -1.0178812e+00\n -4.4890985e+00 -4.4499154e+00  2.8653342e-01  2.0391898e+00\n -1.6920041e-01  5.2400798e-01 -4.8709536e+00 -2.7823212e+00\n -4.3280678e+00 -2.2148230e+00 -4.3944421e+00 -3.8208742e+00\n -3.4446666e+00 -1.7222164e+00 -2.7819488e+00 -2.9122450e+00\n -3.6202753e+00  6.0598767e-01 -3.6765614e+00 -4.0140424e+00\n -3.3209579e+00 -1.1005994e+00 -2.7643225e-01 -5.6338224e+00\n -9.6630239e-01 -1.8759115e+00 -2.3521819e+00 -1.7863389e+00\n -1.4039406e+00 -2.1633394e+00 -3.1201656e+00 -2.7216187e+00\n -2.7281024e+00 -2.1830683e+00 -6.1142459e+00 -3.0204833e+00\n -5.4280454e-01 -1.7481856e+00  1.1813291e+00 -9.1956902e-01\n -3.5288618e+00 -2.9620578e+00 -1.0475310e-01  2.1381934e+00\n -4.8430347e+00 -2.7959943e+00 -1.5639552e+00 -1.2189798e+00\n -4.3197414e-01 -1.3138995e+00 -1.4741604e+00 -4.2477255e+00\n  5.3962862e-01 -3.1513679e+00  1.7850728e+00 -5.0134654e+00\n -1.8334749e+00 -7.0515186e-01 -5.7970750e-01 -3.9227436e+00\n -2.5290163e+00 -2.2264233e+00 -1.5183083e+00 -1.6221555e+00\n -4.2904112e-01 -3.6798215e+00 -3.5050306e+00  8.7500578e-01\n -1.5873286e+00 -4.3919539e+00 -2.6445956e+00 -1.5879468e+00\n -5.9405959e-01 -1.3002276e+00 -2.4275298e+00 -4.4333611e+00\n  3.5615790e+00 -2.6419458e+00 -3.4496155e+00  6.9729462e+00\n  3.6354921e+00 -1.9484106e+00  1.8434908e+00 -1.8927895e+00\n -1.5452069e+00  2.1999696e-01 -6.9028229e-01 -4.2414379e+00\n  2.2799165e+00 -3.4274008e+00 -1.6988693e+00 -4.2199540e+00\n -2.0603168e+00 -3.4022100e+00 -2.7387195e+00 -2.5910950e+00\n  2.2176220e+00 -1.3050113e+00  6.1989598e+00 -2.7798843e+00\n -2.1139958e+00 -2.0281465e+00 -2.9809322e+00  4.6724358e+00\n -3.4105651e+00 -4.4057932e+00  5.4659671e-01 -2.7437749e+00\n -3.0223627e+00 -2.9550862e+00  9.0281449e-02 -2.5569649e+00\n  5.8744317e-01  9.2155226e-02 -1.6554773e+00 -3.0282156e+00\n -4.5606771e-01 -3.6633959e-01 -9.2947960e-01 -2.5414097e+00\n -2.4759457e+00 -4.2071252e+00 -6.0801868e+00  2.7586418e-01\n  4.3230224e+00 -1.1128653e+00 -3.1637990e+00  7.8838623e-01\n -4.0510983e+00 -6.5385258e-01 -5.3992789e-02 -2.4814074e+00\n  1.8379760e-01 -2.1323807e+00 -4.1285176e+00 -4.3440074e-01\n -3.1511481e+00 -1.7326244e+00 -2.3155454e-01  4.7465198e-02\n -9.3367672e-01 -4.6448650e+00 -2.7970572e+00 -2.6494071e+00\n -3.4328526e-01 -4.5774727e+00 -9.8821568e-01 -7.3234636e-01\n -4.1877298e+00 -3.2186248e+00 -4.0624938e+00 -2.1906693e+00\n  5.4304701e-01 -2.9978611e+00  3.0431221e+00 -2.3191891e+00\n -6.8931051e-02  8.3938351e+00 -1.8880205e+00 -2.5566232e+00\n -8.3858466e-01 -2.5671110e+00 -4.3396142e-01 -3.1276128e+00\n -3.4475198e+00 -3.2465963e+00 -4.0633569e+00 -7.5113873e+00\n -3.5836246e+00  4.9751747e-02 -1.7953967e+00 -2.3901623e-01\n  1.8466169e+00  4.0622940e+00 -5.3129244e+00 -1.9117218e+00\n  2.6734695e+00 -3.6774833e+00 -5.1124830e+00 -2.7643316e+00\n  1.3815658e+00 -4.1313620e+00  2.7264378e+00 -1.5558192e-01\n -4.0845335e-02 -1.1757740e+00 -5.0650792e+00 -1.8161966e+00\n -5.3423268e-01 -1.2910435e+00  7.2475994e-01  5.9407568e-01\n -1.2285579e+00 -2.4835703e+00 -1.6285999e+00  2.6052395e-01\n  1.7143499e+00 -3.5942452e+00 -2.8884799e+00 -4.0051246e+00\n -3.2196639e+00 -1.8295245e+00  5.1223326e-01 -7.0626163e-01\n -3.9330454e+00 -3.1770578e-01 -2.2280674e+00 -6.0538025e+00\n  1.1058289e+00 -5.1201153e+00  1.3087488e+00 -3.9981735e-01\n -3.1392620e+00  3.9892993e+00 -3.7718573e+00 -2.5819662e+00\n -5.2637277e+00 -1.2397423e+00  1.1685716e+00 -2.7981911e+00\n -4.6840501e+00 -3.6548841e+00 -3.7537527e+00  3.1288113e-02\n -1.7078738e+00 -5.3499022e+00 -3.5428674e+00 -2.9186103e+00\n -1.3180321e+00  5.4340529e+00 -4.7752638e+00 -2.3788280e+00\n -1.6559899e-02 -9.7215313e-01 -7.3781693e-01 -6.8629801e-01\n -9.7874522e-01 -7.6974779e-01  7.3844308e-01 -4.0834708e+00\n -3.9010470e+00 -1.5001590e+00 -3.8788476e+00 -2.1746492e+00\n -9.8555547e-01 -5.1238406e-01 -1.5875995e+00 -1.0906308e+00\n -7.6636887e-01  1.2533933e+00  7.4113029e-01 -2.0195348e+00\n  1.6032138e+00 -1.6825759e+00  8.5868955e-01 -9.5201534e-01\n -2.3351102e+00  3.3393745e+00 -2.1054888e+00 -2.9180994e+00\n -2.1264777e+00 -2.0685399e+00 -5.3342420e-01  6.3026518e-01\n  1.3690025e+00 -3.0918221e+00 -4.7712436e+00  1.8220634e+00\n -2.5889032e+00 -2.7938271e+00 -3.4848619e+00  5.0482005e-01\n  2.8663638e+00 -2.9479389e+00 -3.7755225e+00  3.8571517e+00\n  1.1357422e+00 -1.1147201e+00 -1.1663015e+00 -2.7979705e+00\n -5.2766542e+00 -3.0663731e+00 -2.7378182e+00  1.2201118e-01\n -7.7789706e-01 -2.7592998e+00 -1.9375327e+00  2.7111340e-02\n  2.3546192e-01  1.5606791e-01 -5.5223856e+00 -2.1874368e+00\n -8.6189806e-01  1.2606708e+00 -5.2966125e-02  5.1558309e+00\n -5.0453824e-01 -4.3313036e+00  1.7646787e+00 -2.5486209e+00\n -3.7736020e+00 -1.9599577e+00 -2.0471752e+00 -2.5638576e+00\n -1.0092226e+00  2.4811065e+00 -2.6492572e+00 -3.0892034e+00\n  2.4489703e+00 -8.6058891e-01 -6.4061254e-01 -6.2572956e+00\n -3.1980715e+00 -1.4776329e+00 -2.1374648e+00  3.4797621e+00\n -7.4177778e-01 -1.2193381e+00 -1.7345785e+00  5.1132063e-03\n  1.4253308e+00  9.5127359e-02 -3.2582004e+00 -1.4071333e+00\n -2.7519395e+00  1.8764343e+00 -6.8902677e-01 -3.7619495e+00\n -1.4388189e+00 -1.2148277e+00 -2.6104827e+00  1.9347938e+00\n  2.7001092e-01 -1.3980728e+00 -4.4715662e+00  7.8806120e-01\n -5.4270196e+00 -1.0676922e+00 -4.2044091e+00 -5.2969885e-01\n -6.3372898e+00 -2.8104205e+00  3.3833361e+00 -2.5058007e+00\n -2.3970687e+00 -5.6405592e+00 -2.9094143e+00 -3.1877863e-01\n -1.7371469e+00 -2.7359350e+00 -3.6501079e+00 -1.9430411e+00\n -7.9828948e-02 -3.9232507e+00 -3.2717352e+00  1.8323456e+00\n -3.0945141e+00 -3.0686839e+00 -4.8254991e+00 -6.4368403e-01\n -2.9707170e+00 -4.6318336e+00 -2.0313132e+00  6.5425283e-01\n -2.4160602e+00 -2.3621473e+00 -4.5858727e+00  6.1263674e-01\n -1.0501320e+00 -1.4476343e+00 -1.0720382e+00 -3.9596753e+00\n -3.7776830e+00 -1.4383219e+00 -3.0732677e+00 -2.1022837e+00\n -1.9204046e+00 -2.9713254e+00 -1.3523822e+00  8.9885797e-03\n -4.2236562e+00 -2.5426385e+00 -8.0880290e-01 -2.6704931e+00\n  3.0349474e+00 -4.8217974e+00 -2.1830723e+00 -5.4794043e-02\n -2.3846807e+00 -2.0510867e+00  2.4600139e+00 -2.9052076e+00\n  6.3329945e+00 -9.6087176e-01 -7.6369262e-01 -1.7106798e+00\n -2.4767666e+00 -3.9139633e+00 -1.9978526e+00  1.5089788e+00\n -2.4276683e+00 -1.1621584e+00 -3.9304488e+00 -1.2055030e+00\n  5.3539997e-01 -1.7801806e+00 -2.8666351e+00 -6.8244755e-01\n  1.0260215e+00 -4.9348646e-01 -1.3140255e-01 -1.6667511e+00\n -2.6473124e+00 -3.8331764e+00 -1.8891780e+00 -2.5004699e+00\n -1.5798080e+00 -8.5195875e-01 -2.5042160e+00 -1.2804494e+00\n -1.2459463e+00 -1.1208673e+00 -2.0905542e+00 -9.4923958e-02\n  1.1930703e+00  8.5317856e-01  4.4032688e+00  4.0019350e+00\n  4.1523632e-01  7.3572546e-01  1.0540587e+00 -2.5120968e-01\n  9.2998421e-01  1.7904966e+00 -1.3486177e+00  8.0633914e-01\n  4.8312372e-01 -8.5601318e-01 -1.2547373e+00 -2.7571945e+00\n -6.8049145e-01 -2.3599148e+00 -1.3818531e-01 -2.5527167e+00\n -1.2411634e+00 -7.4724537e-01 -1.9643520e+00 -3.3836618e-01\n -1.1120626e+00 -1.7412913e+00  3.2453523e+00 -1.7753679e+00\n  1.9378021e+00 -2.7521628e-01 -1.5307586e+00  1.5053518e+00\n -9.9025470e-01 -1.1675348e+00 -1.0547174e+00  8.1667864e-01\n  3.9220229e-01 -2.0835922e+00 -2.5169868e+00 -4.1935763e+00\n -9.7508198e-01  5.5674133e+00  5.8121023e+00  1.3295478e+00\n  3.3260772e+00  5.0068846e+00  3.1887755e+00  5.1851544e+00\n  2.1173346e+00  1.7794693e+00  6.2960691e+00  5.1778574e+00\n  3.6616595e+00  2.4098606e+00  4.4120312e+00 -9.2818856e-01].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `query_features` is your text feature matrix\n",
    "scaler = StandardScaler()\n",
    "normalized_query_features = scaler.fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45534b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # Use the last time step\n",
    "        return out\n",
    "\n",
    "# Example instantiation and usage\n",
    "lstm_model = LSTMModel(input_size=embedding_dim, hidden_size=lstm_units, output_size=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff40c57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def extract_text_features(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()  # Mean pooling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc245add",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"combined_features shape: {combined_features.shape}\")\n",
    "print(f\"labels shape: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835038ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_samples = combined_features.shape[0]\n",
    "num_classes = 5  # Number of categories, adjust as needed\n",
    "\n",
    "# Create labels with the same number of samples as combined_features\n",
    "labels = np.random.randint(0, num_classes, num_samples)\n",
    "\n",
    "print(f\"Updated labels shape: {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23d9c97f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming `image_features` and `text_features` are numpy arrays\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m combined_features \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train a classifier\u001b[39;00m\n\u001b[0;32m      7\u001b[0m classifier \u001b[38;5;241m=\u001b[39m LogisticRegression()\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Assuming `image_features` and `text_features` are numpy arrays\n",
    "combined_features = np.concatenate((features, text_features), axis=1)\n",
    "\n",
    "# Train a classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(combined_features, labels)  # `labels` should be your target variable\n",
    "\n",
    "# Test the classifier\n",
    "predictions = classifier.predict(combined_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5ab40477",
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming `image_features` and `text_features` are numpy arrays\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m combined_features \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Train a classifier\u001b[39;00m\n\u001b[0;32m      7\u001b[0m classifier \u001b[38;5;241m=\u001b[39m LogisticRegression()\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Assuming `image_features` and `text_features` are numpy arrays\n",
    "combined_features = np.concatenate((features, text_features), axis=1)\n",
    "\n",
    "# Train a classifier\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(combined_features, labels)  # `labels` should be your target variable\n",
    "\n",
    "# Test the classifier\n",
    "predictions = classifier.predict(combined_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c23c2330",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "n_components=100 must be between 0 and min(n_samples, n_features)=1 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Reduce dimensionality\u001b[39;00m\n\u001b[0;32m      4\u001b[0m pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m reduced_features \u001b[38;5;241m=\u001b[39m \u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_features\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\utils\\_set_output.py:273\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 273\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    274\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    275\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    276\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    277\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    278\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    279\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:1351\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1344\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1347\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1348\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1349\u001b[0m     )\n\u001b[0;32m   1350\u001b[0m ):\n\u001b[1;32m-> 1351\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\decomposition\\_pca.py:454\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    433\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \n\u001b[0;32m    435\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;124;03m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 454\u001b[0m     U, S, Vt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    455\u001b[0m     U \u001b[38;5;241m=\u001b[39m U[:, : \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_components_]\n\u001b[0;32m    457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwhiten:\n\u001b[0;32m    458\u001b[0m         \u001b[38;5;66;03m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\decomposition\\_pca.py:514\u001b[0m, in \u001b[0;36mPCA._fit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;66;03m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_full\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marpack\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandomized\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_truncated(X, n_components, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_svd_solver)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\decomposition\\_pca.py:530\u001b[0m, in \u001b[0;36mPCA._fit_full\u001b[1;34m(self, X, n_components)\u001b[0m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    527\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmle\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is only supported if n_samples >= n_features\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m         )\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m n_components \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(n_samples, n_features):\n\u001b[1;32m--> 530\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    531\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_components=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m must be between 0 and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin(n_samples, n_features)=\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msvd_solver=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (n_components, \u001b[38;5;28mmin\u001b[39m(n_samples, n_features))\n\u001b[0;32m    534\u001b[0m     )\n\u001b[0;32m    536\u001b[0m \u001b[38;5;66;03m# Center data\u001b[39;00m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_ \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mmean(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: n_components=100 must be between 0 and min(n_samples, n_features)=1 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce dimensionality\n",
    "pca = PCA(n_components=100)\n",
    "reduced_features = pca.fit_transform(combined_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed67db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you need to select a subset of combined_features\n",
    "subset_size = labels.shape[0]\n",
    "combined_features_subset = combined_features[:subset_size]\n",
    "\n",
    "print(f\"Subset combined_features shape: {combined_features_subset.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bfd9ce45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "\n",
    "# Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load pre-trained models\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "cnn_model = models.resnet18(pretrained=True).to(device)\n",
    "cnn_model.eval()\n",
    "\n",
    "# Image preprocessing\n",
    "def preprocess_image(img_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        features = cnn_model(img_tensor)\n",
    "    return features.squeeze().cpu().numpy()\n",
    "\n",
    "# Text feature extraction\n",
    "def extract_text_features(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c75868da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined features shape: (1, 1768)\n"
     ]
    }
   ],
   "source": [
    "# Example data\n",
    "image_path = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\images\\002_0087.jpg\"\n",
    "text_query = 'What\\'s the color?'\n",
    "\n",
    "# Extract features\n",
    "image_features = preprocess_image(image_path)\n",
    "text_features = extract_text_features(text_query)\n",
    "\n",
    "# Ensure they are 2D\n",
    "image_features = image_features.reshape(1, -1)\n",
    "text_features = text_features.reshape(1, -1)\n",
    "\n",
    "# Combine features\n",
    "combined_features = np.concatenate((image_features, text_features), axis=1)\n",
    "\n",
    "print(\"Combined features shape:\", combined_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d4bb716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.40\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Simulated data\n",
    "num_samples = 100  # Sample size\n",
    "num_features_image = 512  # Example number of image features\n",
    "num_features_text = 768  # Example number of text features\n",
    "num_classes = 5\n",
    "\n",
    "# Generate dummy data\n",
    "np.random.seed(102)\n",
    "combined_features = np.random.rand(num_samples, num_features_image + num_features_text)\n",
    "labels = np.random.randint(0, num_classes, num_samples)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(combined_features, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "# Normalization\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "# Dimensionality Reduction\n",
    "pca = PCA(n_components=min(70, X_train_normalized.shape[1]))  # Use 70 or fewer components\n",
    "X_train_reduced = pca.fit_transform(X_train_normalized)\n",
    "X_test_reduced = pca.transform(X_test_normalized)\n",
    "\n",
    "# Train the classifier\n",
    "classifier = LogisticRegression(max_iter=1000)  # Increased max_iter to ensure convergence\n",
    "classifier.fit(X_train_reduced, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "predictions = classifier.predict(X_test_reduced)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b8aa5fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature extraction functions (placeholders)\n",
    "def preprocess_image(image_path):\n",
    "    # Implement image preprocessing and feature extraction\n",
    "    return np.random.rand(num_features_image)\n",
    "\n",
    "def extract_text_features(text_query):\n",
    "    # Implement text feature extraction\n",
    "    return np.random.rand(num_features_text)\n",
    "\n",
    "# Define the model response function\n",
    "def get_model_response(image_path, text_query):\n",
    "    # Extract features\n",
    "    image_features = preprocess_image(image_path)\n",
    "    text_features = extract_text_features(text_query)\n",
    "    \n",
    "    # Ensure the features are 2D arrays\n",
    "    image_features = image_features.reshape(1, -1)  # Convert to 2D array with 1 row\n",
    "    text_features = text_features.reshape(1, -1)  # Convert to 2D array with 1 row\n",
    "    \n",
    "    # Combine features\n",
    "    combined_features = np.concatenate((image_features, text_features), axis=1)\n",
    "    \n",
    "    # Normalize and reduce dimensions\n",
    "    normalized_features = scaler.transform(combined_features)  # Use transform\n",
    "    reduced_features = pca.transform(normalized_features)  # Use transform\n",
    "    \n",
    "    # Classification\n",
    "    prediction = classifier.predict(reduced_features)\n",
    "    return prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4beb3eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response: [3]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "image_path = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\images\\002_0087.jpg\"\n",
    "text_query = 'Whats the color?'\n",
    "response = get_model_response(image_path, text_query)\n",
    "\n",
    "print(f\"Model Response: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a31f6853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Response: [1]\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained text generation model\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "def generate_description(features):\n",
    "    # Create a prompt based on features\n",
    "    prompt = f\"Describe the image with features: {features}\"\n",
    "    \n",
    "    # Tokenize the prompt with a large enough max_length\n",
    "    inputs = tokenizer(prompt, return_tensors='pt', max_length=1024, truncation=True)\n",
    "    \n",
    "    # Generate description\n",
    "    outputs = model.generate(\n",
    "        inputs['input_ids'],\n",
    "        attention_mask=inputs.get('attention_mask'),\n",
    "        max_length=150,  # Adjust this to ensure it does not exceed model capacity\n",
    "        num_return_sequences=1,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=150,  # This parameter helps control the length of the generated output\n",
    "        do_sample=True  # Optional: Enable sampling to get more varied responses\n",
    "    )\n",
    "    \n",
    "    # Decode the generated text\n",
    "    description = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return description\n",
    "\n",
    "# Example usage\n",
    "image_path = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\images\\002_0087.jpg\"\n",
    "text_query = 'What is in the picture?'\n",
    "response = get_model_response(image_path, text_query)\n",
    "\n",
    "print(f\"Model Response: {response}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e4db642",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "# Load BLIP model and processor\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "def generate_description(image_path):\n",
    "    # Load and process the image\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    \n",
    "    # Generate a description\n",
    "    outputs = model.generate(**inputs)\n",
    "    \n",
    "    # Decode the description\n",
    "    description = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "    return description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af888dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\generation\\utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Description: a bird with a yellow beak\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "image_path = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\images\\Lincoln_Sparrow_0023_2887691144.jpg\"\n",
    "description = generate_description(image_path)\n",
    "print(f\"Model Description: {description}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b68310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8d7a2c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image preprocessing and feature extraction complete.\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sequential/embedding/embedding_lookup defined at (most recent call last):\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n\n  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20732\\4178050366.py\", line 101, in <module>\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2655, in predict\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 590, in __call__\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\sequential.py\", line 398, in call\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\functional.py\", line 515, in call\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\functional.py\", line 672, in _run_internal_graph\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 272, in call\n\nindices[5,4] = -1 is not in [0, 10000)\n\t [[{{node sequential/embedding/embedding_lookup}}]] [Op:__inference_predict_function_1061]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 101\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# model.fit(normalized_sequences, labels, epochs=10, batch_size=32)  # Assuming labels are defined\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Combine features for classification\u001b[39;00m\n\u001b[0;32m    100\u001b[0m image_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m512\u001b[39m)  \u001b[38;5;66;03m# Placeholder\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m text_features \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_sequences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    102\u001b[0m combined_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((image_features, text_features), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Normalize and reduce dimensions\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sequential/embedding/embedding_lookup defined at (most recent call last):\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n\n  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20732\\4178050366.py\", line 101, in <module>\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2655, in predict\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 590, in __call__\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\sequential.py\", line 398, in call\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\functional.py\", line 515, in call\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\functional.py\", line 672, in _run_internal_graph\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 272, in call\n\nindices[5,4] = -1 is not in [0, 10000)\n\t [[{{node sequential/embedding/embedding_lookup}}]] [Op:__inference_predict_function_1061]"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from transformers import BertTokenizer, BertModel, GPT2Tokenizer, GPT2LMHeadModel, BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "# Setup paths\n",
    "extract_folder = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\extracted_data\"\n",
    "processed_dir = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\processed_images\"\n",
    "features_dir = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\features\"\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "os.makedirs(features_dir, exist_ok=True)\n",
    "\n",
    "# Image preprocessing function\n",
    "def preprocess_image(img_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_tensor = transform(img).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        features = cnn_model(img_tensor).squeeze().cpu().numpy()\n",
    "    return features\n",
    "\n",
    "# Define feature extraction for text\n",
    "def extract_text_features(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "# Load models\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cnn_model = models.resnet18(pretrained=True).to(device)\n",
    "cnn_model.eval()\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "# Process images and extract features\n",
    "for subdir in os.listdir(extract_folder):\n",
    "    subdir_path = os.path.join(extract_folder, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        for img_name in os.listdir(subdir_path):\n",
    "            img_path = os.path.join(subdir_path, img_name)\n",
    "            if os.path.isfile(img_path):\n",
    "                try:\n",
    "                    features = preprocess_image(img_path)\n",
    "                    np.save(os.path.join(features_dir, img_name.replace('.jpg', '.npy')), features)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process {img_name}: {e}\")\n",
    "\n",
    "print(\"Image preprocessing and feature extraction complete.\")\n",
    "\n",
    "# Load question-response data\n",
    "df = pd.read_csv(r'C:\\Users\\HP\\Desktop\\SIH\\questions_responses.csv')\n",
    "queries = df['Question'].values\n",
    "\n",
    "# Tokenization and padding\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(queries)\n",
    "sequences = tokenizer.texts_to_sequences(queries)\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Normalize sequences\n",
    "def normalize_sequences(sequences):\n",
    "    sequences_np = np.array(sequences, dtype=float)\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(sequences_np)\n",
    "\n",
    "normalized_sequences = normalize_sequences(padded_sequences)\n",
    "\n",
    "# Define and train the LSTM model\n",
    "embedding_dim = 128\n",
    "lstm_units = 64\n",
    "num_classes = 10\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=embedding_dim, input_length=max_length),\n",
    "    LSTM(lstm_units, return_sequences=False),\n",
    "    Dense(lstm_units, activation='relu')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# model.fit(normalized_sequences, labels, epochs=10, batch_size=32)  # Assuming labels are defined\n",
    "\n",
    "# Combine features for classification\n",
    "image_features = np.random.rand(100, 512)  # Placeholder\n",
    "text_features = model.predict(normalized_sequences)\n",
    "combined_features = np.concatenate((image_features, text_features), axis=1)\n",
    "\n",
    "# Normalize and reduce dimensions\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(combined_features)\n",
    "pca = PCA(n_components=100)\n",
    "X_reduced = pca.fit_transform(X_normalized)\n",
    "\n",
    "# Train and evaluate the classifier\n",
    "labels = np.random.randint(0, num_classes, combined_features.shape[0])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, labels, test_size=0.3, random_state=42)\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Define feature extraction and response generation\n",
    "def get_model_response(image_path, text_query):\n",
    "    image_features = preprocess_image(image_path).reshape(1, -1)\n",
    "    text_features = extract_text_features(text_query).reshape(1, -1)\n",
    "    combined_features = np.concatenate((image_features, text_features), axis=1)\n",
    "    normalized_features = scaler.transform(combined_features)\n",
    "    reduced_features = pca.transform(normalized_features)\n",
    "    prediction = classifier.predict(reduced_features)\n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "image_path = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\images\\002_0087.jpg\"\n",
    "text_query = 'What is the color?'\n",
    "response = get_model_response(image_path, text_query)\n",
    "print(f\"Model Response: {response}\")\n",
    "\n",
    "# Generate descriptions\n",
    "def generate_description(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    outputs = model.generate(**inputs)\n",
    "    description = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "    return description\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "description = generate_description(image_path)\n",
    "print(f\"Model Description: {description}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "54b8956b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image preprocessing and feature extraction complete.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "from transformers import BertTokenizer, BertModel, BlipProcessor, BlipForConditionalGeneration\n",
    "\n",
    "# Setup paths\n",
    "extract_folder = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\extracted_data\"\n",
    "processed_dir = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\processed_images\"\n",
    "features_dir = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\features\"\n",
    "\n",
    "# Create directories if not exist\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "os.makedirs(features_dir, exist_ok=True)\n",
    "\n",
    "# Image preprocessing function\n",
    "def preprocess_image(img_path):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        features = cnn_model(img_tensor).squeeze().cpu().numpy()\n",
    "    return features\n",
    "\n",
    "# Define feature extraction for text\n",
    "def extract_text_features(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt').to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "# Load models\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cnn_model = models.resnet18(pretrained=True).to(device)\n",
    "cnn_model.eval()\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "\n",
    "# Process images and extract features\n",
    "for subdir in os.listdir(extract_folder):\n",
    "    subdir_path = os.path.join(extract_folder, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        for img_name in os.listdir(subdir_path):\n",
    "            img_path = os.path.join(subdir_path, img_name)\n",
    "            if os.path.isfile(img_path):\n",
    "                try:\n",
    "                    features = preprocess_image(img_path)\n",
    "                    np.save(os.path.join(features_dir, img_name.replace('.jpg', '.npy')), features)\n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process {img_name}: {e}\")\n",
    "\n",
    "print(\"Image preprocessing and feature extraction complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6474b676",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load question-response data\n",
    "df = pd.read_csv(r'C:\\Users\\HP\\Desktop\\SIH\\questions_responses.csv')\n",
    "queries = df['Question'].values\n",
    "\n",
    "# Tokenization and padding\n",
    "tokenizer = Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(queries)\n",
    "sequences = tokenizer.texts_to_sequences(queries)\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Normalize sequences\n",
    "def normalize_sequences(sequences):\n",
    "    sequences_np = np.array(sequences, dtype=float)\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(sequences_np)\n",
    "\n",
    "normalized_sequences = normalize_sequences(padded_sequences)\n",
    "\n",
    "# Define and train the LSTM model\n",
    "embedding_dim = 128\n",
    "lstm_units = 64\n",
    "num_classes = 10\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=10000, output_dim=embedding_dim, input_length=max_length),\n",
    "    LSTM(lstm_units, return_sequences=False),\n",
    "    Dense(lstm_units, activation='relu')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "818c128f",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node sequential_2/embedding_2/embedding_lookup defined at (most recent call last):\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n\n  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20732\\4164268929.py\", line 8, in <module>\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2655, in predict\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 590, in __call__\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\sequential.py\", line 398, in call\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\functional.py\", line 515, in call\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\functional.py\", line 672, in _run_internal_graph\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 272, in call\n\nindices[5,4] = -1 is not in [0, 10000)\n\t [[{{node sequential_2/embedding_2/embedding_lookup}}]] [Op:__inference_predict_function_3181]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Assuming labels are defined and are available\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# labels = np.array([...]) # Define your labels\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# model.fit(normalized_sequences, labels, epochs=10, batch_size=32)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Combine features for classification\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Replace placeholder with actual image features\u001b[39;00m\n\u001b[0;32m      7\u001b[0m image_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([preprocess_image(img_path) \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(features_dir) \u001b[38;5;28;01mif\u001b[39;00m img_path\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)])\n\u001b[1;32m----> 8\u001b[0m text_features \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnormalized_sequences\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m combined_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((image_features, text_features), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Normalize and reduce dimensions\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node sequential_2/embedding_2/embedding_lookup defined at (most recent call last):\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\runpy.py\", line 196, in _run_module_as_main\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\runpy.py\", line 86, in _run_code\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\asyncio\\events.py\", line 80, in _run\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3051, in run_cell\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3106, in _run_cell\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3311, in run_cell_async\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3493, in run_ast_nodes\n\n  File \"C:\\ProgramData\\anaconda3\\envs\\notebook\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n\n  File \"C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_20732\\4164268929.py\", line 8, in <module>\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2655, in predict\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2440, in predict_function\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2425, in step_function\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2413, in run_step\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 2381, in predict_step\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\training.py\", line 590, in __call__\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\sequential.py\", line 398, in call\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\functional.py\", line 515, in call\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\functional.py\", line 672, in _run_internal_graph\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 65, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\engine\\base_layer.py\", line 1149, in __call__\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 96, in error_handler\n\n  File \"C:\\Users\\HP\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\core\\embedding.py\", line 272, in call\n\nindices[5,4] = -1 is not in [0, 10000)\n\t [[{{node sequential_2/embedding_2/embedding_lookup}}]] [Op:__inference_predict_function_3181]"
     ]
    }
   ],
   "source": [
    "\n",
    "# Assuming labels are defined and are available\n",
    "# labels = np.array([...]) # Define your labels\n",
    "# model.fit(normalized_sequences, labels, epochs=10, batch_size=32)\n",
    "\n",
    "# Combine features for classification\n",
    "# Replace placeholder with actual image features\n",
    "image_features = np.array([preprocess_image(img_path) for img_path in os.listdir(features_dir) if img_path.endswith('.jpg')])\n",
    "text_features = model.predict(normalized_sequences)\n",
    "combined_features = np.concatenate((image_features, text_features), axis=1)\n",
    "\n",
    "# Normalize and reduce dimensions\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(combined_features)\n",
    "pca = PCA(n_components=100)\n",
    "X_reduced = pca.fit_transform(X_normalized)\n",
    "\n",
    "# Train and evaluate the classifier\n",
    "labels = np.random.randint(0, num_classes, combined_features.shape[0])  # Placeholder\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, labels, test_size=0.3, random_state=42)\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "classifier.fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e0ba024",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Tokenizer' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mHP\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDesktop\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mImage Recognitation\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mimages\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m002_0087.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     13\u001b[0m text_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhat is the color?\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 14\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_model_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_query\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Generate descriptions\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[56], line 4\u001b[0m, in \u001b[0;36mget_model_response\u001b[1;34m(image_path, text_query)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_model_response\u001b[39m(image_path, text_query):\n\u001b[0;32m      3\u001b[0m     image_features \u001b[38;5;241m=\u001b[39m preprocess_image(image_path)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     text_features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_text_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_query\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      5\u001b[0m     combined_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate((image_features, text_features), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      6\u001b[0m     normalized_features \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform(combined_features)\n",
      "Cell \u001b[1;32mIn[49], line 42\u001b[0m, in \u001b[0;36mextract_text_features\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_text_features\u001b[39m(text):\n\u001b[1;32m---> 42\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     44\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m bert_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Tokenizer' object is not callable"
     ]
    }
   ],
   "source": [
    "# Define feature extraction and response generation\n",
    "def get_model_response(image_path, text_query):\n",
    "    image_features = preprocess_image(image_path).reshape(1, -1)\n",
    "    text_features = extract_text_features(text_query).reshape(1, -1)\n",
    "    combined_features = np.concatenate((image_features, text_features), axis=1)\n",
    "    normalized_features = scaler.transform(combined_features)\n",
    "    reduced_features = pca.transform(normalized_features)\n",
    "    prediction = classifier.predict(reduced_features)\n",
    "    return prediction\n",
    "\n",
    "# Example usage\n",
    "image_path = r\"C:\\Users\\HP\\Desktop\\Image Recognitation\\images\\002_0087.jpg\"\n",
    "text_query = 'What is the color?'\n",
    "response = get_model_response(image_path, text_query)\n",
    "print(f\"Model Response: {response}\")\n",
    "\n",
    "# Generate descriptions\n",
    "def generate_description(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(**inputs)\n",
    "    description = processor.decode(outputs[0], skip_special_tokens=True)\n",
    "    return description\n",
    "\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
    "description = generate_description(image_path)\n",
    "print(f\"Model Description: {description}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006ed4df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b65832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
